{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/nndb_flat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>ShortDescrip</th>\n",
       "      <th>Descrip</th>\n",
       "      <th>CommonName</th>\n",
       "      <th>MfgName</th>\n",
       "      <th>ScientificName</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>...</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WHIPPED,WITH SALT</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID               FoodGroup              ShortDescrip  \\\n",
       "0  1001  Dairy and Egg Products          BUTTER,WITH SALT   \n",
       "1  1002  Dairy and Egg Products  BUTTER,WHIPPED,WITH SALT   \n",
       "2  1003  Dairy and Egg Products      BUTTER OIL,ANHYDROUS   \n",
       "3  1004  Dairy and Egg Products               CHEESE,BLUE   \n",
       "4  1005  Dairy and Egg Products              CHEESE,BRICK   \n",
       "\n",
       "                      Descrip CommonName MfgName ScientificName  Energy_kcal  \\\n",
       "0              Butter, salted        NaN     NaN            NaN        717.0   \n",
       "1  Butter, whipped, with salt        NaN     NaN            NaN        717.0   \n",
       "2       Butter oil, anhydrous        NaN     NaN            NaN        876.0   \n",
       "3                Cheese, blue        NaN     NaN            NaN        353.0   \n",
       "4               Cheese, brick        NaN     NaN            NaN        371.0   \n",
       "\n",
       "   Protein_g  Fat_g  ...  Folate_USRDA  Niacin_USRDA  Riboflavin_USRDA  \\\n",
       "0       0.85  81.11  ...        0.0075      0.002625          0.026154   \n",
       "1       0.85  81.11  ...        0.0075      0.002625          0.026154   \n",
       "2       0.28  99.48  ...        0.0000      0.000188          0.003846   \n",
       "3      21.40  28.74  ...        0.0900      0.063500          0.293846   \n",
       "4      23.24  29.68  ...        0.0500      0.007375          0.270000   \n",
       "\n",
       "   Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  Magnesium_USRDA  \\\n",
       "0       0.004167       0.020000      0.000000         0.004762   \n",
       "1       0.004167       0.020000      0.000018         0.004762   \n",
       "2       0.000833       0.003333      0.000001         0.000000   \n",
       "3       0.024167       0.440000      0.000044         0.054762   \n",
       "4       0.011667       0.561667      0.000027         0.057143   \n",
       "\n",
       "   Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
       "0          0.034286        0.018182    0.008182  \n",
       "1          0.032857        0.018182    0.004545  \n",
       "2          0.004286        0.000000    0.000909  \n",
       "3          0.552857        0.263636    0.241818  \n",
       "4          0.644286        0.263636    0.236364  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.notnull()\n",
    "data = data.drop(columns=['CommonName','MfgName','ScientificName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>ShortDescrip</th>\n",
       "      <th>Descrip</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>...</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER,WHIPPED,WITH SALT</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Dairy and Egg Products</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID               FoodGroup              ShortDescrip  \\\n",
       "0  1001  Dairy and Egg Products          BUTTER,WITH SALT   \n",
       "1  1002  Dairy and Egg Products  BUTTER,WHIPPED,WITH SALT   \n",
       "2  1003  Dairy and Egg Products      BUTTER OIL,ANHYDROUS   \n",
       "3  1004  Dairy and Egg Products               CHEESE,BLUE   \n",
       "4  1005  Dairy and Egg Products              CHEESE,BRICK   \n",
       "\n",
       "                      Descrip  Energy_kcal  Protein_g  Fat_g  Carb_g  Sugar_g  \\\n",
       "0              Butter, salted        717.0       0.85  81.11    0.06     0.06   \n",
       "1  Butter, whipped, with salt        717.0       0.85  81.11    0.06     0.06   \n",
       "2       Butter oil, anhydrous        876.0       0.28  99.48    0.00     0.00   \n",
       "3                Cheese, blue        353.0      21.40  28.74    2.34     0.50   \n",
       "4               Cheese, brick        371.0      23.24  29.68    2.79     0.51   \n",
       "\n",
       "   Fiber_g  ...  Folate_USRDA  Niacin_USRDA  Riboflavin_USRDA  Thiamin_USRDA  \\\n",
       "0      0.0  ...        0.0075      0.002625          0.026154       0.004167   \n",
       "1      0.0  ...        0.0075      0.002625          0.026154       0.004167   \n",
       "2      0.0  ...        0.0000      0.000188          0.003846       0.000833   \n",
       "3      0.0  ...        0.0900      0.063500          0.293846       0.024167   \n",
       "4      0.0  ...        0.0500      0.007375          0.270000       0.011667   \n",
       "\n",
       "   Calcium_USRDA  Copper_USRDA  Magnesium_USRDA  Phosphorus_USRDA  \\\n",
       "0       0.020000      0.000000         0.004762          0.034286   \n",
       "1       0.020000      0.000018         0.004762          0.032857   \n",
       "2       0.003333      0.000001         0.000000          0.004286   \n",
       "3       0.440000      0.000044         0.054762          0.552857   \n",
       "4       0.561667      0.000027         0.057143          0.644286   \n",
       "\n",
       "   Selenium_USRDA  Zinc_USRDA  \n",
       "0        0.018182    0.008182  \n",
       "1        0.018182    0.004545  \n",
       "2        0.000000    0.000909  \n",
       "3        0.263636    0.241818  \n",
       "4        0.263636    0.236364  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "descrip = np.array(data['Descrip'])\n",
    "words = \"\"\n",
    "for i in descrip:\n",
    "    words += i.lower()+','\n",
    "differentwords = (words.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in differentwords:\n",
    "    if('pizza' in i):\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5952"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(differentwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = np.array(data['FoodGroup'])\n",
    "len(set(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " ' instant breakfast powder',\n",
       " ' 100 grand bar',\n",
       " 'mustard spinach',\n",
       " ' apple and raspberry',\n",
       " ' dark',\n",
       " ' flavored with meat italian sauce',\n",
       " ' with broth',\n",
       " ' 80 proof',\n",
       " 'juice smoothie',\n",
       " ' rolo caramels in milk chocolate',\n",
       " 'p rego pasta',\n",
       " 'fish sticks',\n",
       " 'cattail',\n",
       " ' swordfish',\n",
       " ' royal red',\n",
       " ' mocha-flavor',\n",
       " ' perrier',\n",
       " ' mouvedre',\n",
       " 'next step prosobee',\n",
       " ' cornbread',\n",
       " ' bagel chips',\n",
       " ' berry burst cheerios',\n",
       " ' 3.25% milkfat',\n",
       " ' under blade pot roast or steak',\n",
       " ' grilled chicken & sausage gumbo soup',\n",
       " \" reese's pieces candy\",\n",
       " ' hulled',\n",
       " ' link',\n",
       " ' bacon ranch salad without chicken',\n",
       " ' snack sticks',\n",
       " ' turkey breast (oven roasted',\n",
       " ' original recipe',\n",
       " ' crunchy almond/brown sugar',\n",
       " ' common (danish',\n",
       " ' pork)',\n",
       " 'chives',\n",
       " ' fruit flavored',\n",
       " ' commercially prepared with chocolate frosting',\n",
       " ' silken tofu',\n",
       " ' atlantic',\n",
       " ' peanut butter on cheese crackers',\n",
       " ' pinto bean and hominy',\n",
       " ' dehydrated flakes',\n",
       " ' flap',\n",
       " ' uses similar to high quality cocoa butter',\n",
       " ' skipjack',\n",
       " ' carnation breakfast essentials ',\n",
       " ' without caffeine',\n",
       " ' green variety',\n",
       " ' beefalo',\n",
       " \" sweet 'n sour sauce\",\n",
       " 'keebler',\n",
       " 'rice',\n",
       " ' sweetened with low-calorie sweetener',\n",
       " ' with green chilies',\n",
       " \" hershey's golden almond solitaires\",\n",
       " ' herring eggs',\n",
       " ' rotisserie',\n",
       " ' nutritional shake mix',\n",
       " ' fast roasted',\n",
       " 'eggnog-flavor mix',\n",
       " ' shoulder',\n",
       " ' non fat',\n",
       " ' ready-to-bake',\n",
       " ' waffle cones',\n",
       " 'house foods premium firm tofu',\n",
       " ' (sweetsop)',\n",
       " ' pudding',\n",
       " ' frosted wild grape toaster pastries',\n",
       " ' made with enriched masa flour',\n",
       " ' chow mein',\n",
       " 'vitasoy usa azumaya',\n",
       " ' baby ruth bar',\n",
       " ' (lox)',\n",
       " ' french or vienna',\n",
       " ' corn-based',\n",
       " \"carrabba's italian grill\",\n",
       " ' sweet potatoes strained',\n",
       " ' cocktail',\n",
       " 'milk shakes',\n",
       " ' baked without fat',\n",
       " 'pasta mix',\n",
       " ' loin saddle',\n",
       " ' tri-tip steak',\n",
       " ' mature',\n",
       " ' cheddar cheese soup',\n",
       " \"morningstar farms chik'n grill veggie patties\",\n",
       " ' with pulp',\n",
       " ' mayonnaise type',\n",
       " ' roast',\n",
       " ' ham (chopped with natural juice)',\n",
       " \" kellogg's all-bran bran buds\",\n",
       " ' mango with tapioca',\n",
       " ' next step',\n",
       " 'kraft velveeta pasteurized process cheese spread',\n",
       " ' pork and beef',\n",
       " ' carrots and beef',\n",
       " ' granola bar',\n",
       " ' filled cream-type',\n",
       " ' tofu',\n",
       " ' vitamin d fortified',\n",
       " ' terra chips',\n",
       " ' water and margarine added',\n",
       " ' cinnamon brown sugar baked bites',\n",
       " 'worthington smoked turkey roll',\n",
       " 'new zealand spinach',\n",
       " ' low calorie',\n",
       " ' turkey franks',\n",
       " 'pomegranate juice',\n",
       " ' broad',\n",
       " ' without cheese',\n",
       " ' kidney',\n",
       " ' red leaf',\n",
       " ' blue or roquefort cheese',\n",
       " \" kellogg's crispix\",\n",
       " ' fat free)',\n",
       " 'dill weed',\n",
       " ' denver cut',\n",
       " ' cranberry energy juice drink',\n",
       " ' all purpose',\n",
       " ' beef with country vegetables soup',\n",
       " 'loganberries',\n",
       " 'kellogg',\n",
       " ' 1/2 dipped',\n",
       " ' classic beef',\n",
       " ' sundae',\n",
       " 'vinegar',\n",
       " ' flakes without milk',\n",
       " ' shoulder steak',\n",
       " 'roast beef',\n",
       " 'silk very vanilla',\n",
       " ' back meat and skin',\n",
       " ' snickers cruncher',\n",
       " ' diluted with 3 volume water without added ascorbic acid',\n",
       " ' surimi',\n",
       " ' prepared with tap water',\n",
       " ' grape',\n",
       " ' propel zero',\n",
       " ' boiled (northern plains indians)',\n",
       " ' sausage mcmuffin with egg',\n",
       " ' salami (for beer)',\n",
       " 'brussels sprouts',\n",
       " ' with added oil',\n",
       " ' eas soy protein powder',\n",
       " ' 85% lean',\n",
       " ' without added sodium or vitamin a',\n",
       " ' wieners (cheese hot dogs with turkey)',\n",
       " ' salami (genoa)',\n",
       " ' good start soy',\n",
       " ' and cheese',\n",
       " ' tilapia',\n",
       " ' chunky chicken noodle',\n",
       " ' starburst sour fruit chews',\n",
       " ' sunchips',\n",
       " 'pineapple and grapefruit juice drink',\n",
       " ' farley fruit snacks',\n",
       " ' club & cheddar sandwich crackers',\n",
       " ' lasagna classico',\n",
       " ' pinot noir',\n",
       " ' cream of asparagus',\n",
       " ' cheerios',\n",
       " ' sugar syrup/caramel',\n",
       " ' nutz over chocolate',\n",
       " ' composite of separable fat',\n",
       " ' pop',\n",
       " ' soy oil (partially hydrogenated )',\n",
       " \" baker's treasures\",\n",
       " ' 95% lean meat / 5% fat',\n",
       " ' made from reduced fat packaged mix',\n",
       " ' tomato bisque',\n",
       " ' salada brewed from bags',\n",
       " ' pizza',\n",
       " ' bite-size',\n",
       " 'watercress',\n",
       " ' dinner',\n",
       " ' cream of onion soup',\n",
       " ' rib roast',\n",
       " ' chicken mushroom chowder',\n",
       " ' just bunches',\n",
       " ' vegetable soup',\n",
       " ' confectioners coating',\n",
       " ' lil crunchies',\n",
       " ' raisin vineyard',\n",
       " ' classic double',\n",
       " ' blended with cookie pieces',\n",
       " ' dark chocolate coated coffee beans',\n",
       " ' pregestimil',\n",
       " 'cowpeas (blackeyes)',\n",
       " ' 100 calorie right bites',\n",
       " ' peanut bar',\n",
       " ' reduced-calorie or diet',\n",
       " ' pm 60/40',\n",
       " 'whale',\n",
       " ' arm pot roast',\n",
       " ' slim-a-bear',\n",
       " ' sponge',\n",
       " 'beans',\n",
       " 'braunschweiger (a liver sausage)',\n",
       " ' toasteds',\n",
       " ' quaker',\n",
       " ' extra firm',\n",
       " ' mountain dew original',\n",
       " 'chili',\n",
       " ' curd cheese',\n",
       " ' peanut butter on toasty crackers',\n",
       " ' manhattan style',\n",
       " ' golden crisp',\n",
       " 'pizza hut 12\" pepperoni pizza',\n",
       " 'frybread',\n",
       " ' smoked sliced beef',\n",
       " ' wheat and honey',\n",
       " ' pasta with cheese filling',\n",
       " ' special dietary',\n",
       " ' chicken and chipotle bbq sauce with mango',\n",
       " ' solids and liquid',\n",
       " ' popcorn',\n",
       " 'beverages',\n",
       " ' prime',\n",
       " ' cinnamon nut)',\n",
       " ' boiled with salt',\n",
       " \"campbell's healthy request\",\n",
       " ' frijoles with cheese',\n",
       " 'vitasoy usa organic nasoya sprouted',\n",
       " ' 96% lean / 4% fat',\n",
       " ' cracker chips',\n",
       " ' (alaska native)',\n",
       " '  trimmed to 1/8\" fat',\n",
       " ' eel',\n",
       " ' great grains crunchy pecan cereal',\n",
       " ' bun length)',\n",
       " ' club crackers',\n",
       " ' egg yolks and bacon',\n",
       " ' breast',\n",
       " ' banana and strawberry',\n",
       " ' high-fat',\n",
       " ' yane (alaska native)',\n",
       " ' farmed',\n",
       " ' italian style wedding soup',\n",
       " ' betty crocker supermoist yellow cake mix',\n",
       " ' potato ham chowder',\n",
       " ' corn based',\n",
       " \"morningstar farms chik'n nuggets\",\n",
       " ' restaurant-prepared',\n",
       " ' herb and laborador combination (alaska native)',\n",
       " ' mature seeds',\n",
       " ' top loin filet',\n",
       " 'chokecherries',\n",
       " ' walleye',\n",
       " ' classic chicken noodle soup',\n",
       " ' garden',\n",
       " 'breakfast tart',\n",
       " ' quaker crunchy bran',\n",
       " ' neufchatel',\n",
       " ' sesame seed kernels',\n",
       " ' vitamins a and d',\n",
       " ' without ice',\n",
       " ' with cream style corn',\n",
       " ' chicken',\n",
       " ' quick',\n",
       " ' merry mint patties',\n",
       " ' soft taco with ground beef',\n",
       " ' and olive',\n",
       " ' principal use flaky pastries',\n",
       " ' inside skirt',\n",
       " ' plum',\n",
       " ' plums',\n",
       " ' milk chocolate peanut',\n",
       " 'sea cucumber',\n",
       " \" kellogg's rice krispies\",\n",
       " ' mexican rice',\n",
       " ' ringed',\n",
       " ' sesame chicken',\n",
       " 'chicken tenders',\n",
       " ' calcium-fortified',\n",
       " ' baked apple pie',\n",
       " 'garlic',\n",
       " ' liquid',\n",
       " 'swanson broth',\n",
       " ' sucker',\n",
       " ' lightly frosted',\n",
       " ' mace',\n",
       " \" kellogg's cinnamon jacks\",\n",
       " 'alfalfa seeds',\n",
       " \"campbell's homestyle new england clam chowder\",\n",
       " 'lasagna with meat & sauce',\n",
       " ' pink',\n",
       " ' caramel filled cookies',\n",
       " ' pollock',\n",
       " ' special dietary (includes lemon-flavored)',\n",
       " ' high oleic (70% and over)',\n",
       " 'endive',\n",
       " ' with wheat flour added',\n",
       " ' cinnamon with crumb topping',\n",
       " ' eastern',\n",
       " 'chicken breast',\n",
       " ' with fruit and granola',\n",
       " ' country-style ribs',\n",
       " ' 85% lean meat / 15% fat',\n",
       " ' with corn syrup and/or sugar and low calorie sweetener',\n",
       " \" kellogg's product 19\",\n",
       " ' potherb',\n",
       " 'v8 v. fusion juices',\n",
       " ' fore-shank',\n",
       " ' very low sodium',\n",
       " ' crispbread',\n",
       " ' medallion',\n",
       " ' beef and mushroom',\n",
       " ' oven-roasted',\n",
       " 'vinespinach',\n",
       " 'pie',\n",
       " ' side salad',\n",
       " ' apple yogurt dessert',\n",
       " ' oregano',\n",
       " ' cheddar or american',\n",
       " 'lamb',\n",
       " ' japanese',\n",
       " ' from raw and stone ground kernels',\n",
       " ' salted and fermented (fuyu)',\n",
       " ' 98% fat free vanilla',\n",
       " ' carp',\n",
       " ' sprite',\n",
       " \"kraft breakstone's reduced fat sour cream\",\n",
       " ' organic promise autumn wheat',\n",
       " ' nutty clusters & almonds',\n",
       " 'acerola juice',\n",
       " ' prepared from granules',\n",
       " ' whiskey) 80 proof',\n",
       " ' vitasoy organic creamy original soymilk',\n",
       " ' 3 musketeers bar',\n",
       " ' with beef and cheese',\n",
       " ' mamey',\n",
       " ' vanilla with nuts',\n",
       " ' fudge stripes',\n",
       " 'silk nog',\n",
       " 'lotus root',\n",
       " ' meat and skin and breading',\n",
       " ' shortbread bites',\n",
       " ' thin',\n",
       " ' slimfast',\n",
       " ' chicken broth or bouillon',\n",
       " ' horse',\n",
       " ' less than 3% juice',\n",
       " ' quaker oatmeal to go',\n",
       " ' french toaster sticks',\n",
       " ' soybean oil and butter',\n",
       " ' custard pudding',\n",
       " 'frozen novelties',\n",
       " ' milk chocolate covered',\n",
       " ' original seasoning',\n",
       " ' with apples',\n",
       " ' top round cap-off steak/roast',\n",
       " 'interstate brands corp',\n",
       " ' whole (arm and blade)',\n",
       " ' beef with white and wild rice soup',\n",
       " 'popeyes',\n",
       " ' fenugreek seed',\n",
       " ' fiber 7 flakes',\n",
       " ' 14\" pizza',\n",
       " ' flavored',\n",
       " ' chicken broth cubes',\n",
       " 'corn with red and green peppers',\n",
       " ' thick-cut',\n",
       " ' regular (10 minute)',\n",
       " ' unfortified',\n",
       " ' healthy request mexican style tortilla',\n",
       " ' ice cream shoppe frosted rainbow chip toaster pastries',\n",
       " ' brined (alaska native)',\n",
       " ' potatoes',\n",
       " ' apple - cherry',\n",
       " ' chicken fajita strips',\n",
       " 'bockwurst',\n",
       " ' latino bakery item',\n",
       " \"wend'ys\",\n",
       " ' microwavable',\n",
       " ' with bananas',\n",
       " \" kellogg's frosted mini-wheats touch of fruit in the middle mixed berry\",\n",
       " ' frosted pumpkin pie toaster pastries',\n",
       " ' jacks vanilla wafers',\n",
       " ' green pea soup',\n",
       " 'fruit butters',\n",
       " ' assorted',\n",
       " 'prego pasta',\n",
       " 'ostrich',\n",
       " ' butter or sugar',\n",
       " ' coffee',\n",
       " ' 98% fat free cream of chicken soup',\n",
       " ' chicken fingers',\n",
       " ' butter (includes fresh and frozen)',\n",
       " 'tomato products',\n",
       " ' hot fudge sundae',\n",
       " ' chocolatey chip thins cookies',\n",
       " ' chicken fettuccine',\n",
       " ' chump off',\n",
       " ' fresh pork',\n",
       " ' drained solids',\n",
       " ' hazelnut',\n",
       " ' hot mustard sauce',\n",
       " ' made with palm oil',\n",
       " ' unenriched',\n",
       " ' kashi golean crunch!',\n",
       " ' simmered',\n",
       " ' ice cream shoppe frosted hot fudge sundae toaster pastries',\n",
       " ' 1% fat',\n",
       " ' junior',\n",
       " ' savory chicken with white & wild rice soup',\n",
       " ' with iron and fiber (formerly ross)',\n",
       " ' coconut cream',\n",
       " ' with chicory',\n",
       " 'salsify',\n",
       " \" kellogg's special k chocolatey strawberry\",\n",
       " ' ling',\n",
       " ' supreme topping',\n",
       " \" kellogg's honey smacks\",\n",
       " ' peach melba',\n",
       " 'meat drippings (lard',\n",
       " ' hain celestial group',\n",
       " ' mcchicken sandwich',\n",
       " ' coconut dreams cookies',\n",
       " ' and sugar',\n",
       " ' monterey',\n",
       " ' cream of shrimp soup',\n",
       " ' pre-basted',\n",
       " 'cereals ready-to-eat',\n",
       " ' savory herb crackers',\n",
       " ' cherry',\n",
       " ' fruit pudding',\n",
       " ' not breaded',\n",
       " ' potato',\n",
       " ' almonds',\n",
       " ' beef sticks',\n",
       " 'worthington multigrain cutlets',\n",
       " ' batter',\n",
       " ' fully hydrogenated',\n",
       " ' somen',\n",
       " 'peaches',\n",
       " 'radish seeds',\n",
       " ' and grape popsicle pops',\n",
       " ' v8 60% vegetable juice',\n",
       " ' ready-to-drink',\n",
       " 'elk',\n",
       " ' breadnut tree seeds',\n",
       " 'orange breakfast drink',\n",
       " ' chopped or leaf',\n",
       " ' lentil soup',\n",
       " ' cooked (southwest)',\n",
       " ' with hydrogenated vegetable oil and soy protein',\n",
       " 'frog legs',\n",
       " ' grass-fed',\n",
       " 'shake',\n",
       " ' nutramigen aa',\n",
       " ' packed in tomato juice',\n",
       " ' multi-grain (includes whole-grain)',\n",
       " ' cereal',\n",
       " ' sun country',\n",
       " ' regular',\n",
       " 'peach nectar',\n",
       " ' quesadilla',\n",
       " ' mustard',\n",
       " ' cottage-cut',\n",
       " ' cookie-like',\n",
       " ' frosted mini-wheats bite size strawberry delight',\n",
       " ' without calcium propionate(includes sourdough)',\n",
       " ' vegetables and chicken',\n",
       " ' prune and orange',\n",
       " ' kc masterpiece',\n",
       " ' edible-podded',\n",
       " ' boneless separable lean only',\n",
       " ' chocolate caramel',\n",
       " ' made from dried potatoes',\n",
       " ' organic mushroom italian sauce',\n",
       " ' black bean soup',\n",
       " ' whelk',\n",
       " ' roasted almond',\n",
       " ' oatmeal',\n",
       " ' pepper-type',\n",
       " ' vegetables and beef',\n",
       " ' farina',\n",
       " \"mcdonald's bacon ranch salad with crispy chicken\",\n",
       " ' chicken gumbo soup',\n",
       " ' bread',\n",
       " ' pumpernickel',\n",
       " 'morningstar farms entree chili',\n",
       " ' soda',\n",
       " ' bologna (fat free)',\n",
       " ' (tendergreen)',\n",
       " ' fudgesicle pops',\n",
       " ' pasta with vegetables',\n",
       " ' creme-filled',\n",
       " ' smooth',\n",
       " ' trimmed to 1/8\" fat',\n",
       " ' apple and cherry',\n",
       " ' vegetable oil spread',\n",
       " ' puffs or twists',\n",
       " ' water',\n",
       " ' homestyle chicken fillet sandwich',\n",
       " ' peanut flavor',\n",
       " \" pop'ables milky way brand bite size candies\",\n",
       " 'cranberry-apple juice drink',\n",
       " ' cultured',\n",
       " ' naturally sparkling',\n",
       " ' white-winged',\n",
       " ' frosted raspberry',\n",
       " ' corn on the cob with butter',\n",
       " ' from dark meat',\n",
       " ' chex mix',\n",
       " ' chuck',\n",
       " ' rabbit',\n",
       " 'margarine-like spread with yogurt',\n",
       " ' jellied',\n",
       " 'morningstar farms roasted garlic & quinoa burger',\n",
       " ' cucumber',\n",
       " ' skittles original bite size candies',\n",
       " ' green peppers',\n",
       " 'chicken spread',\n",
       " ' grape juice',\n",
       " ' quick (1-3 minutes)',\n",
       " ' hash brown rounds',\n",
       " ' baked and topped with sour cream and chives',\n",
       " 'papayas',\n",
       " ' franks (turkey and chicken cheese)',\n",
       " ' commercially prepared',\n",
       " ' onion-flavor',\n",
       " ' fresh water',\n",
       " ' grape-nuts cereal',\n",
       " ' eggo seasons',\n",
       " ' cod',\n",
       " ' shark',\n",
       " ' dry heat',\n",
       " ' ranch-flavor',\n",
       " \" cap'n crunch with crunchberries\",\n",
       " ' apples',\n",
       " ' chicken)',\n",
       " ' broiled (northern plains indians)',\n",
       " ' dark meat (drumstick or thigh)',\n",
       " ' mini brownies',\n",
       " ' frozen concentrate',\n",
       " 'peppers',\n",
       " ' deluxe grahams cookies',\n",
       " 'lemonade-flavor drink',\n",
       " ' snickers marathon protein performance bar',\n",
       " ' eggs (alaska native)',\n",
       " \" hershey's genuine chocolate flavored lite syrup\",\n",
       " ' golden seedless',\n",
       " ' berry berry kix',\n",
       " ' and shoulder)',\n",
       " ' vegetable and brown rice',\n",
       " ' (vegetable oyster)',\n",
       " ' healthy request vegetable soup',\n",
       " 'apples',\n",
       " 'edamame',\n",
       " ' mini mints grasshopper cookies',\n",
       " 'carob-flavor beverage mix',\n",
       " ' italian dressing',\n",
       " ' cake-type',\n",
       " ' butternut',\n",
       " ' niacin',\n",
       " ' little bites',\n",
       " 'bread sticks',\n",
       " ' usda commodity corn and rice (includes all commodity brands)',\n",
       " ' (pineapple and papaya and banana and guava)',\n",
       " \"morningstar farms mushroom lover's burger\",\n",
       " ' original chicken sandwich',\n",
       " ' flavored and sweetened',\n",
       " ' late harvest',\n",
       " \"mcdonald's\",\n",
       " 'quinoa',\n",
       " ' vegetables chicken',\n",
       " \" general tso's chicken\",\n",
       " ' chicken and stars soup',\n",
       " ' outside round',\n",
       " ' minis original crackers',\n",
       " ' oriental',\n",
       " ' center cut chops',\n",
       " ' french fries',\n",
       " ' golden puffs',\n",
       " 'morningstar farms grillers quarter pound veggie burger',\n",
       " \"campbell's homestyle mexican style chicken tortilla soup\",\n",
       " 'quail',\n",
       " ' tap',\n",
       " ' premium',\n",
       " ' la moderna rikis cream crackers',\n",
       " 'kashi pizza',\n",
       " ' regular flavor',\n",
       " \" newman's own low fat balsamic vinaigrette\",\n",
       " ' with franks',\n",
       " ' with low calorie sweetener',\n",
       " ' chicken a la king',\n",
       " 'fiddlehead ferns',\n",
       " ' southwestern-style chicken w/rice (chicken not included)',\n",
       " ' steak cut',\n",
       " '  85% lean / 15% fat',\n",
       " ' teaseed',\n",
       " ' not canned',\n",
       " ' pound cake type',\n",
       " ' tonic water',\n",
       " 'egg substitute',\n",
       " ' mechanically deboned',\n",
       " 'worthington saucettes',\n",
       " 'dessert topping',\n",
       " ' lemon-lime flavored',\n",
       " \"campbell's chicken gravy\",\n",
       " ' caffeine free',\n",
       " ' almond milk',\n",
       " 'citrus fruit juice drink',\n",
       " ' familia',\n",
       " ' stuffed crust',\n",
       " ' arm picnic',\n",
       " 'horseradish',\n",
       " ' vegetable and fruit juice blend',\n",
       " ' (granadilla)',\n",
       " ' banana (navajo)',\n",
       " ' milk chocolate peanut butter and soft nougats',\n",
       " 'pork and turkey sausage',\n",
       " ' canned in tomato sauce',\n",
       " ' dumpling with mutton (navajo)',\n",
       " 'fruit flavored drink containing less than 3% fruit juice',\n",
       " ' pearled',\n",
       " \" split pea 'n' ham soup\",\n",
       " ' carving board)',\n",
       " ' onion',\n",
       " ' french lentil',\n",
       " 'orange peel',\n",
       " \" m&m's semisweet chocolate mini baking bits\",\n",
       " \"campbell's red and white\",\n",
       " 'chili con carne with beans',\n",
       " 'little caesars 14\" cheese pizza',\n",
       " ' hard type',\n",
       " 'pimento',\n",
       " 'oopah (tunicate)',\n",
       " ' peanut butter gauchos cookies',\n",
       " ' cheese)',\n",
       " ' with corn flour coating (corndog)',\n",
       " ' double chocolate cookies',\n",
       " \" pop'ables snickers brand bite size candies\",\n",
       " ' strawberry',\n",
       " ' soft taco',\n",
       " 'morningstar farms grillers burger style recipe crumbles',\n",
       " ' top round',\n",
       " ' sun-dried',\n",
       " ' wheat germ',\n",
       " ' home prepared',\n",
       " ' cottonseed flour',\n",
       " 'mixed vegetable and fruit juice drink',\n",
       " ' wafers with peanut butter',\n",
       " ' cooked with water',\n",
       " ' harvard',\n",
       " ' egg drop',\n",
       " ' oat blenders with honey',\n",
       " ' prepared with butter',\n",
       " ' in-store bakery',\n",
       " ' tilefish',\n",
       " ' salted',\n",
       " ' nut and raisin',\n",
       " ' meat and skin',\n",
       " ' enriched',\n",
       " ' monster',\n",
       " ' milk',\n",
       " ' sazon',\n",
       " ' traditional flavor',\n",
       " 'morningstar farms grillers prime',\n",
       " 'cranberry-grape juice drink',\n",
       " 'okara',\n",
       " ' precooked or instant',\n",
       " 'silk coffee',\n",
       " 'baby food',\n",
       " ' or banana powder',\n",
       " ' high vitamin c and added thiamin',\n",
       " ' whole grain',\n",
       " ' stick',\n",
       " ' potato wedges',\n",
       " ' unspecified oils',\n",
       " ' prepared with water or ready-to-serve',\n",
       " ' reduced-calorie',\n",
       " ' and beans',\n",
       " ' cookie crumb topping',\n",
       " \" kellogg's all-bran original\",\n",
       " ' croaker',\n",
       " ' summer sausage thuringer cervalat',\n",
       " 'celeriac',\n",
       " ' klondike',\n",
       " ' total can contents',\n",
       " ' canola',\n",
       " ' ultimate deep dish crust',\n",
       " ' veal',\n",
       " \"kellogg's eggo lowfat blueberry nutri-grain waffles\",\n",
       " ' gumdrops',\n",
       " ' duoz smoked cheddar monterey jack crackers',\n",
       " ' blueberry muffin tops cereal',\n",
       " ' spaghetti in tomato & cheese sauce',\n",
       " ' eggo minis',\n",
       " ' vegetables and mayonnaise',\n",
       " ' dha and ara',\n",
       " ' high oleic (70%)',\n",
       " ' whiskey) 94 proof',\n",
       " ' twix chocolate fudge cookie bars',\n",
       " ' without meat',\n",
       " \" pop'ables 3 musketeers brand bite size candies\",\n",
       " ' unsweetened',\n",
       " ' organic nasoya silken tofu',\n",
       " 'hush puppies',\n",
       " ' grouper',\n",
       " ' peaches',\n",
       " 'pace',\n",
       " ' turkey vegetable',\n",
       " ' unenriched flour',\n",
       " ' magic middles fudge filled cookies',\n",
       " ' quick oats',\n",
       " ' chicken vegetable soup',\n",
       " ' shank',\n",
       " ' pourable liquid fry shortening',\n",
       " 'little caesars 14\" original round pepperoni pizza',\n",
       " ' triple patty',\n",
       " ' cookie crisp',\n",
       " ' chardonnay',\n",
       " \"morningstar farms italian herb chik'n pattie\",\n",
       " ' cooked (includes squab)',\n",
       " ' heated (microwave)',\n",
       " ' tootie fruities',\n",
       " ' banana yogurt',\n",
       " ' flowers',\n",
       " ' subcutaneous fat (blubber) (alaska native)',\n",
       " 'prairie turnips',\n",
       " ' raisin nut bran',\n",
       " ' classic tomato soup',\n",
       " ' apricot',\n",
       " ' fish',\n",
       " 'ice cream sandwich',\n",
       " ' oats',\n",
       " ' neck',\n",
       " 'pumpkin leaves',\n",
       " ' soy (partially hydrogenated ) and corn for frying',\n",
       " ' (pigeon)',\n",
       " 'cauliflower',\n",
       " ' toppers',\n",
       " ' zucchini',\n",
       " ' cream',\n",
       " ' thompson seedless',\n",
       " 'sweet potato leaves',\n",
       " ' with chicken',\n",
       " ' beef tallow',\n",
       " ' pediasure',\n",
       " ' cheese-filled',\n",
       " ' chocolate with frosting',\n",
       " ' romano',\n",
       " ' round pieces or patty',\n",
       " ' naked juice',\n",
       " ' frosted wild strawberry toaster pastries',\n",
       " ' peanut butter sandwich',\n",
       " ' fudge shoppe',\n",
       " ' granulated',\n",
       " ' freeze-dried',\n",
       " ' rainbow chocolate chip cookies',\n",
       " ' blueberry hazelnut',\n",
       " 'yogurt',\n",
       " ' taro chips',\n",
       " ' smoked link sausage',\n",
       " ' salami (hard)',\n",
       " ' with juice and pulp',\n",
       " ' cola',\n",
       " ' oven-heated',\n",
       " ' with vitamin e added',\n",
       " ' chervil',\n",
       " ' chunky garden combination italian sauce',\n",
       " ' swanson chicken broth 99% fat free',\n",
       " ' choco zucaritas',\n",
       " ' hamburger or hotdog',\n",
       " ' holiday circus animal cookies',\n",
       " 'wocas',\n",
       " ' cake',\n",
       " ' dry form',\n",
       " ' packets',\n",
       " ' salpora de arroz con azucar',\n",
       " 'potato pancakes',\n",
       " ' carignane',\n",
       " ' puffed',\n",
       " ' pasta',\n",
       " ' glazed',\n",
       " ' smokies sausage little cheese (pork',\n",
       " ' fan fillet',\n",
       " ' kashi tlc bar',\n",
       " ' healthy request chicken with mini noodles soup',\n",
       " ' made with egg',\n",
       " ' lima',\n",
       " ' roasting',\n",
       " ' coconut water',\n",
       " ' tofu plus extra firm',\n",
       " 'butter replacement',\n",
       " ' dices',\n",
       " ' honey nut cheerios',\n",
       " ' shoulder)',\n",
       " 'salmon',\n",
       " ' poppy',\n",
       " ' vanilla wafers',\n",
       " ' candy bits',\n",
       " ' bbq',\n",
       " ' peanut butter cups cookies',\n",
       " ' brownberry sage and onion stuffing mix',\n",
       " ' compressed',\n",
       " ' self-rising',\n",
       " ' tip side',\n",
       " ' from whole',\n",
       " 'silk hazelnut creamer',\n",
       " ' pilaf',\n",
       " 'rice flour',\n",
       " ' cool nestea ice tea lemon flavor',\n",
       " ' white popcorn',\n",
       " ' nutritional shake',\n",
       " ' extra crispy',\n",
       " ' vegetables and turkey',\n",
       " ' regular patty; with condiments and vegetables',\n",
       " 'croutons',\n",
       " ' french fried in vegetable oil',\n",
       " 'french toast',\n",
       " ' mashed',\n",
       " ' ricotta',\n",
       " ' rusk toast',\n",
       " ' mixed',\n",
       " ' tenderloin steak/roast',\n",
       " 'beet greens',\n",
       " ' coho (silver)',\n",
       " ' unenriched (includes honey buns)',\n",
       " ' unbaked',\n",
       " ' wing meat and skin',\n",
       " ' rice bran',\n",
       " ' without added salt',\n",
       " 'fast foods',\n",
       " ' microwave',\n",
       " ' sugar-coated almonds',\n",
       " ' animal',\n",
       " ' ready-to-feed',\n",
       " 'silk key lime soy yogurt',\n",
       " ' starburst fruit chews',\n",
       " ' coconut custard',\n",
       " ' fried chicken',\n",
       " ' yumberry',\n",
       " ' sweet yeast bread',\n",
       " 'abiyuch',\n",
       " ' powder',\n",
       " ' in oil (alaska native)',\n",
       " ' boston (steaks)',\n",
       " ' bimbo bakeries usa',\n",
       " ' with cheese filling',\n",
       " ' frozen (liquid expressed from grated meat and water)',\n",
       " ' g performance o 2',\n",
       " ' patty; plain',\n",
       " ' fortified cereal bar',\n",
       " ' wieners (light pork',\n",
       " 'cloudberries',\n",
       " ' dannon',\n",
       " ' semi solid',\n",
       " ' traditional varieties',\n",
       " 'ham and cheese spread',\n",
       " \" tony's smartpizza whole grain 4x6 cheese pizza 50/50 cheese- frozen\",\n",
       " ' ripe',\n",
       " ' grilled sirloin steak with hearty vegetables soup',\n",
       " ' canola harvest soft spread (canola',\n",
       " ' ribeye  petite roast/filet',\n",
       " ' vegetables and ham',\n",
       " ' prepared with water and ice',\n",
       " ' oh henry! bar',\n",
       " ' with dha and ara (formerly ross)',\n",
       " ' contains wheat flour and rice flour',\n",
       " ' after eight mints',\n",
       " ' extra lean and regular',\n",
       " 'v8 splash smoothies',\n",
       " ' ham -- water added',\n",
       " 'breadfruit',\n",
       " ' cinnamon crunch',\n",
       " ' bottom sirloin butt',\n",
       " 'mouse nuts',\n",
       " ' with coconut',\n",
       " ' aust. marble score 9',\n",
       " ' includes plain and from mutton sandwich (navajo)',\n",
       " ' oat cluster cheerios crunch',\n",
       " ' claret',\n",
       " 'kellogg mini-wheats frosted bite size touch of fruit raisin',\n",
       " ' soybean oil',\n",
       " ' (skunk cabbage)',\n",
       " ' top loin petite roast',\n",
       " ' not from concentrate',\n",
       " \" o'brien\",\n",
       " ' extra firm tofu',\n",
       " ' meat-filled',\n",
       " 'pokeberry shoots',\n",
       " ' contains caffeine',\n",
       " ' soymilk',\n",
       " ' orange-flavor drink',\n",
       " ' store brand',\n",
       " ' young green',\n",
       " ' reduced sugar frosted flakes cereal',\n",
       " 'soy flour',\n",
       " ' soy',\n",
       " 'cranberries',\n",
       " 'asparagus',\n",
       " 'barley',\n",
       " ' wagyu',\n",
       " ' pasteurized',\n",
       " ' monkfish',\n",
       " 'yardlong bean',\n",
       " ' peppers',\n",
       " ' kashi go lean hot cereal',\n",
       " \" kellogg's special k\",\n",
       " ' honey bunches of oats with vanilla bunches',\n",
       " ' sea salt',\n",
       " ' ribeye petite roast',\n",
       " ' plain (alaska native)',\n",
       " ' with added vitamin d',\n",
       " ' all natural light vanilla chocolate strawberry',\n",
       " ' boneless separable lean and fat',\n",
       " ' chunky garden mushroom and green pepper italian sauce',\n",
       " 'balsam-pear (bitter gourd)',\n",
       " ' infant',\n",
       " ' soybean without cholesterol',\n",
       " ' evaporated',\n",
       " ' cream cheese-flavor',\n",
       " ' glaze',\n",
       " 'pectin',\n",
       " ' wieners (beef franks',\n",
       " ' chocolate creme sandwich cookies',\n",
       " 'butcher boy meats',\n",
       " 'melon balls',\n",
       " ' sausage biscuit with egg',\n",
       " 'silk blueberry soy yogurt',\n",
       " ' chicken alphabet soup',\n",
       " 'whipped cream substitute',\n",
       " ' burbot',\n",
       " ' iced cookies',\n",
       " ' spoon-size',\n",
       " ' chocolate mousse',\n",
       " 'radishes',\n",
       " ' scotch',\n",
       " ' milk chocolate coated raisins',\n",
       " 'soy sauce made from hydrolyzed vegetable protein',\n",
       " ' watermelon seed kernels',\n",
       " ' non-alcoholic',\n",
       " 'baking chocolate',\n",
       " \" hearty bean 'n' ham soup\",\n",
       " 'fluid replacement',\n",
       " ' cheese enchilada',\n",
       " ' degermed',\n",
       " ' muller thurgau',\n",
       " 'buffalo',\n",
       " 'strawberries',\n",
       " ' lentil with ham',\n",
       " ' ground bulk/coarse ground',\n",
       " ' frosted wild berry',\n",
       " 'cheesefurter',\n",
       " ' whiskey) 86 proof',\n",
       " ' thomas english muffins',\n",
       " ' chicken and dumplings',\n",
       " ' shortbread pie crust',\n",
       " ' peanuts (for sundaes)',\n",
       " ' seedlings (alaska native)',\n",
       " ' extra light syrup',\n",
       " ' thank u berry munch cookies',\n",
       " 'broccoli',\n",
       " ' brownies',\n",
       " 'bread',\n",
       " ' blade (chops or roasts)',\n",
       " ' cinnamon rolls with icing',\n",
       " ' cinnamon crisp',\n",
       " ' chocolate almond snack bar',\n",
       " ' with cauliflower onion mustard',\n",
       " ' energy drink',\n",
       " ' plate',\n",
       " ' heart',\n",
       " ' zinfandel',\n",
       " 'sapote',\n",
       " 'sapodilla',\n",
       " ' truffles',\n",
       " ' mixed fruit',\n",
       " ' steam meal',\n",
       " ' soup)',\n",
       " ' diluted with 3 volume water',\n",
       " ' back ribs',\n",
       " 'shortening',\n",
       " ' red taco sauce',\n",
       " ' good start 2 essentials',\n",
       " 'winged bean tuber',\n",
       " ' oatmeal dark chocolate cookies',\n",
       " ' egg and onion',\n",
       " ' tuna',\n",
       " ' and red chili peppers',\n",
       " ' honey buzzers',\n",
       " ' cheese on wheat sandwich crackers',\n",
       " ' dried (prunes)',\n",
       " 'worthington vegetarian burger',\n",
       " ' turkey and rice',\n",
       " ' chocolate malt powder',\n",
       " 'duck',\n",
       " ' creamy chicken noodle soup',\n",
       " ' enriched (n x 5.70)',\n",
       " ' and giblets and neck',\n",
       " ' stock',\n",
       " ' nutmeg butter',\n",
       " 'silk plus omega-3 dha',\n",
       " ' sweet',\n",
       " 'gardenburger sun-dried tomato basil burger',\n",
       " 'beef sausage',\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(differentwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'American Indian/Alaska Native Foods',\n",
       " 'Baby Foods',\n",
       " 'Baked Products',\n",
       " 'Beef Products',\n",
       " 'Beverages',\n",
       " 'Breakfast Cereals',\n",
       " 'Cereal Grains and Pasta',\n",
       " 'Dairy and Egg Products',\n",
       " 'Fast Foods',\n",
       " 'Fats and Oils',\n",
       " 'Finfish and Shellfish Products',\n",
       " 'Fruits and Fruit Juices',\n",
       " 'Lamb, Veal, and Game Products',\n",
       " 'Legumes and Legume Products',\n",
       " 'Meals, Entrees, and Side Dishes',\n",
       " 'Nut and Seed Products',\n",
       " 'Pork Products',\n",
       " 'Poultry Products',\n",
       " 'Restaurant Foods',\n",
       " 'Sausages and Luncheon Meats',\n",
       " 'Snacks',\n",
       " 'Soups, Sauces, and Gravies',\n",
       " 'Spices and Herbs',\n",
       " 'Sweets',\n",
       " 'Vegetables and Vegetable Products'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonveg = [\n",
    " 'American Indian/Alaska Native Foods',\n",
    " 'Beef Products',\n",
    " 'Dairy and Egg Products',\n",
    " 'Finfish and Shellfish Products',\n",
    " 'Lamb, Veal, and Game Products',\n",
    " 'Pork Products',\n",
    " 'Poultry Products',\n",
    " 'Sausages and Luncheon Meats',]\n",
    "remove = ['Restaurant Foods','Meals, Entrees, and Side Dishes', 'Fast Foods', 'Baked Products',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlabels = []\n",
    "index = []\n",
    "j = 0\n",
    "for i in groups:\n",
    "    if(i in nonveg):\n",
    "        newlabels.append('Non-Veg')\n",
    "    elif(i in remove):\n",
    "        newlabels.append('Remove')\n",
    "        index.append(j)\n",
    "    else:\n",
    "        newlabels.append('Veg')\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " 'Non-Veg',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1389"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Non-Veg': 3057, 'Veg': 4172, 'Remove': 1389})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(newlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['FoodGroup'] = newlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>FoodGroup</th>\n",
       "      <th>ShortDescrip</th>\n",
       "      <th>Descrip</th>\n",
       "      <th>Energy_kcal</th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>...</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>Non-Veg</td>\n",
       "      <td>BUTTER,WITH SALT</td>\n",
       "      <td>Butter, salted</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>Non-Veg</td>\n",
       "      <td>BUTTER,WHIPPED,WITH SALT</td>\n",
       "      <td>Butter, whipped, with salt</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>Non-Veg</td>\n",
       "      <td>BUTTER OIL,ANHYDROUS</td>\n",
       "      <td>Butter oil, anhydrous</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>Non-Veg</td>\n",
       "      <td>CHEESE,BLUE</td>\n",
       "      <td>Cheese, blue</td>\n",
       "      <td>353.0</td>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>Non-Veg</td>\n",
       "      <td>CHEESE,BRICK</td>\n",
       "      <td>Cheese, brick</td>\n",
       "      <td>371.0</td>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID FoodGroup              ShortDescrip                     Descrip  \\\n",
       "0  1001   Non-Veg          BUTTER,WITH SALT              Butter, salted   \n",
       "1  1002   Non-Veg  BUTTER,WHIPPED,WITH SALT  Butter, whipped, with salt   \n",
       "2  1003   Non-Veg      BUTTER OIL,ANHYDROUS       Butter oil, anhydrous   \n",
       "3  1004   Non-Veg               CHEESE,BLUE                Cheese, blue   \n",
       "4  1005   Non-Veg              CHEESE,BRICK               Cheese, brick   \n",
       "\n",
       "   Energy_kcal  Protein_g  Fat_g  Carb_g  Sugar_g  Fiber_g  ...  Folate_USRDA  \\\n",
       "0        717.0       0.85  81.11    0.06     0.06      0.0  ...        0.0075   \n",
       "1        717.0       0.85  81.11    0.06     0.06      0.0  ...        0.0075   \n",
       "2        876.0       0.28  99.48    0.00     0.00      0.0  ...        0.0000   \n",
       "3        353.0      21.40  28.74    2.34     0.50      0.0  ...        0.0900   \n",
       "4        371.0      23.24  29.68    2.79     0.51      0.0  ...        0.0500   \n",
       "\n",
       "   Niacin_USRDA  Riboflavin_USRDA  Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  \\\n",
       "0      0.002625          0.026154       0.004167       0.020000      0.000000   \n",
       "1      0.002625          0.026154       0.004167       0.020000      0.000018   \n",
       "2      0.000188          0.003846       0.000833       0.003333      0.000001   \n",
       "3      0.063500          0.293846       0.024167       0.440000      0.000044   \n",
       "4      0.007375          0.270000       0.011667       0.561667      0.000027   \n",
       "\n",
       "   Magnesium_USRDA  Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
       "0         0.004762          0.034286        0.018182    0.008182  \n",
       "1         0.004762          0.032857        0.018182    0.004545  \n",
       "2         0.000000          0.004286        0.000000    0.000909  \n",
       "3         0.054762          0.552857        0.263636    0.241818  \n",
       "4         0.057143          0.644286        0.263636    0.236364  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacopy = copy.deepcopy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['FoodGroup'] != 'Remove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7229"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['ShortDescrip','Descrip','ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = data['Energy_kcal']\n",
    "label = data['FoodGroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Energy_kcal','FoodGroup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>...</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein_g  Fat_g  Carb_g  Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  \\\n",
       "0       0.85  81.11    0.06     0.06      0.0     684.0     0.003        0.17   \n",
       "1       0.85  81.11    0.06     0.06      0.0     684.0     0.003        0.13   \n",
       "2       0.28  99.48    0.00     0.00      0.0     840.0     0.001        0.01   \n",
       "3      21.40  28.74    2.34     0.50      0.0     198.0     0.166        1.22   \n",
       "4      23.24  29.68    2.79     0.51      0.0     292.0     0.065        1.26   \n",
       "\n",
       "   VitC_mg  VitE_mg  ...  Folate_USRDA  Niacin_USRDA  Riboflavin_USRDA  \\\n",
       "0      0.0     2.32  ...        0.0075      0.002625          0.026154   \n",
       "1      0.0     2.32  ...        0.0075      0.002625          0.026154   \n",
       "2      0.0     2.80  ...        0.0000      0.000188          0.003846   \n",
       "3      0.0     0.25  ...        0.0900      0.063500          0.293846   \n",
       "4      0.0     0.26  ...        0.0500      0.007375          0.270000   \n",
       "\n",
       "   Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  Magnesium_USRDA  \\\n",
       "0       0.004167       0.020000      0.000000         0.004762   \n",
       "1       0.004167       0.020000      0.000018         0.004762   \n",
       "2       0.000833       0.003333      0.000001         0.000000   \n",
       "3       0.024167       0.440000      0.000044         0.054762   \n",
       "4       0.011667       0.561667      0.000027         0.057143   \n",
       "\n",
       "   Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
       "0          0.034286        0.018182    0.008182  \n",
       "1          0.032857        0.018182    0.004545  \n",
       "2          0.004286        0.000000    0.000909  \n",
       "3          0.552857        0.263636    0.241818  \n",
       "4          0.644286        0.263636    0.236364  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting in 70:30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data,energy, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "y_pred_test = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2169, 2169)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test),len(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_metrics(y_test,y_pred):\n",
    "    print(\"MSE: \" + str(mean_squared_error(y_test, y_pred)) +\"\\n\" )\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE: \"+str(rmse)+\"\\n\")\n",
    "    mae=mean_absolute_error(y_test, y_pred)\n",
    "    print(\"MAE: \"+str(mae)+\"\\n\")\n",
    "    r2score=r2_score(y_test,y_pred)\n",
    "    print(\"r2score: \"+str(r2score)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 286.0931502955001\n",
      "\n",
      "RMSE: 16.914288347296793\n",
      "\n",
      "MAE: 6.678435049967229\n",
      "\n",
      "r2score: 0.989927967989939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_metrics(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = LassoCV(max_iter = 40000, cv = 20)\n",
    "lasso = lasso.fit(x_train, y_train)\n",
    "y_pred_test = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 282.0348041566524\n",
      "\n",
      "RMSE: 16.79389187045851\n",
      "\n",
      "MAE: 6.763150189569077\n",
      "\n",
      "r2score: 0.990070843805652\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_metrics(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "#from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference - https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33\n",
    "NN_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Input Layer :\n",
    "NN_model.add(Dense(128,input_dim = data.shape[1], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))\n",
    "NN_model.add(Dense(256,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Output Layer :\n",
    "NN_model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 128)               4864      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               256       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 334,850\n",
      "Trainable params: 334,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3542 samples, validate on 1518 samples\n",
      "Epoch 1/500\n",
      "3542/3542 [==============================] - 1s 296us/step - loss: 17.8622 - mean_absolute_error: 17.8622 - val_loss: 7.1799 - val_mean_absolute_error: 7.1799\n",
      "Epoch 2/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 6.2703 - mean_absolute_error: 6.2703 - val_loss: 7.5367 - val_mean_absolute_error: 7.5367\n",
      "Epoch 3/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 5.4750 - mean_absolute_error: 5.4750 - val_loss: 8.2409 - val_mean_absolute_error: 8.2409\n",
      "Epoch 4/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 5.8710 - mean_absolute_error: 5.8710 - val_loss: 6.9536 - val_mean_absolute_error: 6.9536\n",
      "Epoch 5/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 6.0260 - mean_absolute_error: 6.0260 - val_loss: 8.1742 - val_mean_absolute_error: 8.1742\n",
      "Epoch 6/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 6.1798 - mean_absolute_error: 6.1798 - val_loss: 6.9700 - val_mean_absolute_error: 6.9700\n",
      "Epoch 7/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 5.9673 - mean_absolute_error: 5.9673 - val_loss: 7.2401 - val_mean_absolute_error: 7.2401\n",
      "Epoch 8/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 5.5548 - mean_absolute_error: 5.5548 - val_loss: 6.7632 - val_mean_absolute_error: 6.7632\n",
      "Epoch 9/500\n",
      "3542/3542 [==============================] - 1s 177us/step - loss: 5.5606 - mean_absolute_error: 5.5606 - val_loss: 8.3126 - val_mean_absolute_error: 8.3126\n",
      "Epoch 10/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 5.1387 - mean_absolute_error: 5.1387 - val_loss: 7.7599 - val_mean_absolute_error: 7.7599\n",
      "Epoch 11/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 5.4698 - mean_absolute_error: 5.4698 - val_loss: 7.0013 - val_mean_absolute_error: 7.0013\n",
      "Epoch 12/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 5.6300 - mean_absolute_error: 5.6300 - val_loss: 7.6468 - val_mean_absolute_error: 7.6468\n",
      "Epoch 13/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 5.7219 - mean_absolute_error: 5.7219 - val_loss: 7.1282 - val_mean_absolute_error: 7.1282\n",
      "Epoch 14/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 5.3739 - mean_absolute_error: 5.3739 - val_loss: 8.9158 - val_mean_absolute_error: 8.9158\n",
      "Epoch 15/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 5.4960 - mean_absolute_error: 5.4960 - val_loss: 7.0781 - val_mean_absolute_error: 7.0781\n",
      "Epoch 16/500\n",
      "3542/3542 [==============================] - 1s 244us/step - loss: 5.6508 - mean_absolute_error: 5.6508 - val_loss: 7.7092 - val_mean_absolute_error: 7.7092\n",
      "Epoch 17/500\n",
      "3542/3542 [==============================] - 1s 229us/step - loss: 5.4321 - mean_absolute_error: 5.4321 - val_loss: 6.7531 - val_mean_absolute_error: 6.7531\n",
      "Epoch 18/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 5.2246 - mean_absolute_error: 5.2246 - val_loss: 8.2907 - val_mean_absolute_error: 8.2907\n",
      "Epoch 19/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 5.5482 - mean_absolute_error: 5.5482 - val_loss: 8.2108 - val_mean_absolute_error: 8.2108\n",
      "Epoch 20/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 5.9605 - mean_absolute_error: 5.9605 - val_loss: 8.3486 - val_mean_absolute_error: 8.3486\n",
      "Epoch 21/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 5.6068 - mean_absolute_error: 5.6068 - val_loss: 13.2863 - val_mean_absolute_error: 13.2863\n",
      "Epoch 22/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 5.2672 - mean_absolute_error: 5.2672 - val_loss: 8.8627 - val_mean_absolute_error: 8.8627\n",
      "Epoch 23/500\n",
      "3542/3542 [==============================] - 1s 193us/step - loss: 5.8686 - mean_absolute_error: 5.8686 - val_loss: 8.2971 - val_mean_absolute_error: 8.2971\n",
      "Epoch 24/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 5.0503 - mean_absolute_error: 5.0503 - val_loss: 6.8417 - val_mean_absolute_error: 6.8417\n",
      "Epoch 25/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.9810 - mean_absolute_error: 4.9810 - val_loss: 7.1062 - val_mean_absolute_error: 7.1062\n",
      "Epoch 26/500\n",
      "3542/3542 [==============================] - 1s 273us/step - loss: 6.0964 - mean_absolute_error: 6.0964 - val_loss: 9.4223 - val_mean_absolute_error: 9.4223\n",
      "Epoch 27/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 5.4862 - mean_absolute_error: 5.4862 - val_loss: 7.3613 - val_mean_absolute_error: 7.3613\n",
      "Epoch 28/500\n",
      "3542/3542 [==============================] - 1s 229us/step - loss: 5.1072 - mean_absolute_error: 5.1072 - val_loss: 7.6287 - val_mean_absolute_error: 7.6287\n",
      "Epoch 29/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 5.1844 - mean_absolute_error: 5.1844 - val_loss: 8.9316 - val_mean_absolute_error: 8.9316\n",
      "Epoch 30/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 5.3804 - mean_absolute_error: 5.3804 - val_loss: 6.9958 - val_mean_absolute_error: 6.9958\n",
      "Epoch 31/500\n",
      "3542/3542 [==============================] - 1s 255us/step - loss: 5.8208 - mean_absolute_error: 5.8208 - val_loss: 7.3898 - val_mean_absolute_error: 7.3898\n",
      "Epoch 32/500\n",
      "3542/3542 [==============================] - 1s 278us/step - loss: 5.4701 - mean_absolute_error: 5.4701 - val_loss: 7.1366 - val_mean_absolute_error: 7.1366\n",
      "Epoch 33/500\n",
      "3542/3542 [==============================] - 1s 227us/step - loss: 5.1646 - mean_absolute_error: 5.1646 - val_loss: 7.8945 - val_mean_absolute_error: 7.8945\n",
      "Epoch 34/500\n",
      "3542/3542 [==============================] - 1s 210us/step - loss: 5.4571 - mean_absolute_error: 5.4571 - val_loss: 7.0811 - val_mean_absolute_error: 7.0811\n",
      "Epoch 35/500\n",
      "3542/3542 [==============================] - 1s 165us/step - loss: 6.2520 - mean_absolute_error: 6.2520 - val_loss: 7.3915 - val_mean_absolute_error: 7.3915\n",
      "Epoch 36/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 5.2758 - mean_absolute_error: 5.2758 - val_loss: 7.7241 - val_mean_absolute_error: 7.7241\n",
      "Epoch 37/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 5.5456 - mean_absolute_error: 5.5456 - val_loss: 10.6964 - val_mean_absolute_error: 10.6964\n",
      "Epoch 38/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 5.0955 - mean_absolute_error: 5.0955 - val_loss: 7.8669 - val_mean_absolute_error: 7.8669\n",
      "Epoch 39/500\n",
      "3542/3542 [==============================] - 1s 176us/step - loss: 5.0032 - mean_absolute_error: 5.0032 - val_loss: 7.6828 - val_mean_absolute_error: 7.6828\n",
      "Epoch 40/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 5.3445 - mean_absolute_error: 5.3445 - val_loss: 7.3150 - val_mean_absolute_error: 7.3150\n",
      "Epoch 41/500\n",
      "3542/3542 [==============================] - 1s 190us/step - loss: 5.7248 - mean_absolute_error: 5.7248 - val_loss: 7.2524 - val_mean_absolute_error: 7.2524\n",
      "Epoch 42/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 4.9826 - mean_absolute_error: 4.9826 - val_loss: 7.2253 - val_mean_absolute_error: 7.2253\n",
      "Epoch 43/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.5917 - mean_absolute_error: 4.5917 - val_loss: 7.1039 - val_mean_absolute_error: 7.1039\n",
      "Epoch 44/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 5.9543 - mean_absolute_error: 5.9543 - val_loss: 9.7017 - val_mean_absolute_error: 9.7017\n",
      "Epoch 45/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 6.3159 - mean_absolute_error: 6.3159 - val_loss: 10.5430 - val_mean_absolute_error: 10.5430\n",
      "Epoch 46/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 5.6780 - mean_absolute_error: 5.6780 - val_loss: 7.3805 - val_mean_absolute_error: 7.3805\n",
      "Epoch 47/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 5.2443 - mean_absolute_error: 5.2443 - val_loss: 8.1626 - val_mean_absolute_error: 8.1626\n",
      "Epoch 48/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 5.6853 - mean_absolute_error: 5.6853 - val_loss: 7.2806 - val_mean_absolute_error: 7.2806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "3542/3542 [==============================] - 1s 193us/step - loss: 5.4109 - mean_absolute_error: 5.4109 - val_loss: 10.1390 - val_mean_absolute_error: 10.1390\n",
      "Epoch 50/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 5.2627 - mean_absolute_error: 5.2627 - val_loss: 7.9408 - val_mean_absolute_error: 7.9408\n",
      "Epoch 51/500\n",
      "3542/3542 [==============================] - 1s 210us/step - loss: 5.1550 - mean_absolute_error: 5.1550 - val_loss: 7.1784 - val_mean_absolute_error: 7.1784\n",
      "Epoch 52/500\n",
      "3542/3542 [==============================] - 1s 219us/step - loss: 4.6065 - mean_absolute_error: 4.6065 - val_loss: 9.5384 - val_mean_absolute_error: 9.5384\n",
      "Epoch 53/500\n",
      "3542/3542 [==============================] - 1s 223us/step - loss: 5.4869 - mean_absolute_error: 5.4869 - val_loss: 7.2285 - val_mean_absolute_error: 7.2285\n",
      "Epoch 54/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 6.1572 - mean_absolute_error: 6.1572 - val_loss: 9.1327 - val_mean_absolute_error: 9.1327\n",
      "Epoch 55/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 5.2079 - mean_absolute_error: 5.2079 - val_loss: 6.6720 - val_mean_absolute_error: 6.6720\n",
      "Epoch 56/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 5.4795 - mean_absolute_error: 5.4795 - val_loss: 6.8603 - val_mean_absolute_error: 6.8603\n",
      "Epoch 57/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 5.8091 - mean_absolute_error: 5.8091 - val_loss: 8.3655 - val_mean_absolute_error: 8.3655\n",
      "Epoch 58/500\n",
      "3542/3542 [==============================] - 1s 166us/step - loss: 4.8422 - mean_absolute_error: 4.8422 - val_loss: 10.2744 - val_mean_absolute_error: 10.2744\n",
      "Epoch 59/500\n",
      "3542/3542 [==============================] - 1s 167us/step - loss: 5.4505 - mean_absolute_error: 5.4505 - val_loss: 6.7702 - val_mean_absolute_error: 6.7702\n",
      "Epoch 60/500\n",
      "3542/3542 [==============================] - 1s 165us/step - loss: 4.9722 - mean_absolute_error: 4.9722 - val_loss: 6.8223 - val_mean_absolute_error: 6.8223\n",
      "Epoch 61/500\n",
      "3542/3542 [==============================] - 1s 168us/step - loss: 5.4389 - mean_absolute_error: 5.4389 - val_loss: 8.2779 - val_mean_absolute_error: 8.2779\n",
      "Epoch 62/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 5.2441 - mean_absolute_error: 5.2441 - val_loss: 6.9876 - val_mean_absolute_error: 6.9875\n",
      "Epoch 63/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 5.5003 - mean_absolute_error: 5.5003 - val_loss: 9.3454 - val_mean_absolute_error: 9.3454\n",
      "Epoch 64/500\n",
      "3542/3542 [==============================] - 1s 164us/step - loss: 5.8591 - mean_absolute_error: 5.8591 - val_loss: 8.1852 - val_mean_absolute_error: 8.1852\n",
      "Epoch 65/500\n",
      "3542/3542 [==============================] - 1s 165us/step - loss: 5.5489 - mean_absolute_error: 5.5489 - val_loss: 9.2917 - val_mean_absolute_error: 9.2917\n",
      "Epoch 66/500\n",
      "3542/3542 [==============================] - 1s 163us/step - loss: 4.8040 - mean_absolute_error: 4.8040 - val_loss: 6.6075 - val_mean_absolute_error: 6.6075\n",
      "Epoch 67/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 4.8078 - mean_absolute_error: 4.8078 - val_loss: 6.7043 - val_mean_absolute_error: 6.7043\n",
      "Epoch 68/500\n",
      "3542/3542 [==============================] - 1s 199us/step - loss: 4.8546 - mean_absolute_error: 4.8546 - val_loss: 7.8998 - val_mean_absolute_error: 7.8998\n",
      "Epoch 69/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.9120 - mean_absolute_error: 4.9120 - val_loss: 6.7718 - val_mean_absolute_error: 6.7718\n",
      "Epoch 70/500\n",
      "3542/3542 [==============================] - 1s 167us/step - loss: 6.5330 - mean_absolute_error: 6.5330 - val_loss: 10.8534 - val_mean_absolute_error: 10.8534\n",
      "Epoch 71/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.9744 - mean_absolute_error: 4.9744 - val_loss: 7.2321 - val_mean_absolute_error: 7.2321\n",
      "Epoch 72/500\n",
      "3542/3542 [==============================] - 1s 194us/step - loss: 4.7113 - mean_absolute_error: 4.7113 - val_loss: 9.1882 - val_mean_absolute_error: 9.1882\n",
      "Epoch 73/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 5.2663 - mean_absolute_error: 5.2663 - val_loss: 6.8501 - val_mean_absolute_error: 6.8501\n",
      "Epoch 74/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.7265 - mean_absolute_error: 4.7265 - val_loss: 7.4955 - val_mean_absolute_error: 7.4955\n",
      "Epoch 75/500\n",
      "3542/3542 [==============================] - 1s 232us/step - loss: 4.7684 - mean_absolute_error: 4.7684 - val_loss: 6.9646 - val_mean_absolute_error: 6.9646\n",
      "Epoch 76/500\n",
      "3542/3542 [==============================] - 1s 191us/step - loss: 4.9163 - mean_absolute_error: 4.9163 - val_loss: 10.3867 - val_mean_absolute_error: 10.3867\n",
      "Epoch 77/500\n",
      "3542/3542 [==============================] - 1s 222us/step - loss: 5.2146 - mean_absolute_error: 5.2146 - val_loss: 10.1271 - val_mean_absolute_error: 10.1271\n",
      "Epoch 78/500\n",
      "3542/3542 [==============================] - 1s 209us/step - loss: 5.5814 - mean_absolute_error: 5.5814 - val_loss: 7.3633 - val_mean_absolute_error: 7.3633\n",
      "Epoch 79/500\n",
      "3542/3542 [==============================] - 1s 190us/step - loss: 5.0480 - mean_absolute_error: 5.0480 - val_loss: 6.4300 - val_mean_absolute_error: 6.4300\n",
      "Epoch 80/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.4886 - mean_absolute_error: 4.4886 - val_loss: 8.1728 - val_mean_absolute_error: 8.1728\n",
      "Epoch 81/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.8525 - mean_absolute_error: 4.8525 - val_loss: 7.1350 - val_mean_absolute_error: 7.1350\n",
      "Epoch 82/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 6.0853 - mean_absolute_error: 6.0853 - val_loss: 9.8817 - val_mean_absolute_error: 9.8817\n",
      "Epoch 83/500\n",
      "3542/3542 [==============================] - 1s 227us/step - loss: 5.0395 - mean_absolute_error: 5.0395 - val_loss: 9.1707 - val_mean_absolute_error: 9.1707\n",
      "Epoch 84/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 4.9000 - mean_absolute_error: 4.9000 - val_loss: 7.5032 - val_mean_absolute_error: 7.5032\n",
      "Epoch 85/500\n",
      "3542/3542 [==============================] - 1s 252us/step - loss: 4.9694 - mean_absolute_error: 4.9694 - val_loss: 6.9106 - val_mean_absolute_error: 6.9106\n",
      "Epoch 86/500\n",
      "3542/3542 [==============================] - 1s 286us/step - loss: 4.3900 - mean_absolute_error: 4.3900 - val_loss: 6.9350 - val_mean_absolute_error: 6.9350\n",
      "Epoch 87/500\n",
      "3542/3542 [==============================] - 1s 238us/step - loss: 4.8918 - mean_absolute_error: 4.8918 - val_loss: 6.9837 - val_mean_absolute_error: 6.9837\n",
      "Epoch 88/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.8619 - mean_absolute_error: 4.8619 - val_loss: 6.8194 - val_mean_absolute_error: 6.8194\n",
      "Epoch 89/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 5.5389 - mean_absolute_error: 5.5389 - val_loss: 8.6276 - val_mean_absolute_error: 8.6276\n",
      "Epoch 90/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 5.4611 - mean_absolute_error: 5.4611 - val_loss: 7.0307 - val_mean_absolute_error: 7.0307\n",
      "Epoch 91/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.8020 - mean_absolute_error: 4.8020 - val_loss: 6.8979 - val_mean_absolute_error: 6.8979\n",
      "Epoch 92/500\n",
      "3542/3542 [==============================] - 1s 267us/step - loss: 4.7659 - mean_absolute_error: 4.7659 - val_loss: 6.9609 - val_mean_absolute_error: 6.9609\n",
      "Epoch 93/500\n",
      "3542/3542 [==============================] - 1s 248us/step - loss: 5.2116 - mean_absolute_error: 5.2116 - val_loss: 6.7082 - val_mean_absolute_error: 6.7082\n",
      "Epoch 94/500\n",
      "3542/3542 [==============================] - 1s 252us/step - loss: 4.6136 - mean_absolute_error: 4.6136 - val_loss: 6.7761 - val_mean_absolute_error: 6.7761\n",
      "Epoch 95/500\n",
      "3542/3542 [==============================] - 1s 257us/step - loss: 4.3014 - mean_absolute_error: 4.3014 - val_loss: 6.8148 - val_mean_absolute_error: 6.8148\n",
      "Epoch 96/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.9643 - mean_absolute_error: 4.9643 - val_loss: 6.9255 - val_mean_absolute_error: 6.9255\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3542/3542 [==============================] - 1s 203us/step - loss: 4.8577 - mean_absolute_error: 4.8577 - val_loss: 7.2191 - val_mean_absolute_error: 7.2191\n",
      "Epoch 98/500\n",
      "3542/3542 [==============================] - 1s 248us/step - loss: 5.0723 - mean_absolute_error: 5.0723 - val_loss: 7.2615 - val_mean_absolute_error: 7.2615\n",
      "Epoch 99/500\n",
      "3542/3542 [==============================] - 1s 362us/step - loss: 4.6032 - mean_absolute_error: 4.6032 - val_loss: 7.2658 - val_mean_absolute_error: 7.2658\n",
      "Epoch 100/500\n",
      "3542/3542 [==============================] - 1s 282us/step - loss: 5.2956 - mean_absolute_error: 5.2956 - val_loss: 7.4507 - val_mean_absolute_error: 7.4507\n",
      "Epoch 101/500\n",
      "3542/3542 [==============================] - 1s 306us/step - loss: 5.1738 - mean_absolute_error: 5.1738 - val_loss: 6.7266 - val_mean_absolute_error: 6.7266\n",
      "Epoch 102/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 5.4600 - mean_absolute_error: 5.4600 - val_loss: 6.7901 - val_mean_absolute_error: 6.7901\n",
      "Epoch 103/500\n",
      "3542/3542 [==============================] - 1s 240us/step - loss: 4.5899 - mean_absolute_error: 4.5899 - val_loss: 7.0144 - val_mean_absolute_error: 7.0144\n",
      "Epoch 104/500\n",
      "3542/3542 [==============================] - 1s 199us/step - loss: 5.0397 - mean_absolute_error: 5.0397 - val_loss: 7.7986 - val_mean_absolute_error: 7.7986\n",
      "Epoch 105/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 4.6915 - mean_absolute_error: 4.6915 - val_loss: 7.3344 - val_mean_absolute_error: 7.3344\n",
      "Epoch 106/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.6493 - mean_absolute_error: 4.6493 - val_loss: 6.9021 - val_mean_absolute_error: 6.9021\n",
      "Epoch 107/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 4.9568 - mean_absolute_error: 4.9568 - val_loss: 6.7160 - val_mean_absolute_error: 6.7160\n",
      "Epoch 108/500\n",
      "3542/3542 [==============================] - 1s 218us/step - loss: 4.4625 - mean_absolute_error: 4.4625 - val_loss: 6.6169 - val_mean_absolute_error: 6.6169\n",
      "Epoch 109/500\n",
      "3542/3542 [==============================] - 1s 223us/step - loss: 4.6377 - mean_absolute_error: 4.6377 - val_loss: 6.9541 - val_mean_absolute_error: 6.9541\n",
      "Epoch 110/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 5.1422 - mean_absolute_error: 5.1422 - val_loss: 6.7151 - val_mean_absolute_error: 6.7151\n",
      "Epoch 111/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 5.0896 - mean_absolute_error: 5.0896 - val_loss: 7.3883 - val_mean_absolute_error: 7.3883\n",
      "Epoch 112/500\n",
      "3542/3542 [==============================] - 1s 190us/step - loss: 4.9933 - mean_absolute_error: 4.9933 - val_loss: 6.7625 - val_mean_absolute_error: 6.7625\n",
      "Epoch 113/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.6592 - mean_absolute_error: 4.6592 - val_loss: 8.1392 - val_mean_absolute_error: 8.1392\n",
      "Epoch 114/500\n",
      "3542/3542 [==============================] - 1s 217us/step - loss: 4.6268 - mean_absolute_error: 4.6268 - val_loss: 7.1477 - val_mean_absolute_error: 7.1477\n",
      "Epoch 115/500\n",
      "3542/3542 [==============================] - 1s 291us/step - loss: 4.7905 - mean_absolute_error: 4.7905 - val_loss: 6.8682 - val_mean_absolute_error: 6.8681\n",
      "Epoch 116/500\n",
      "3542/3542 [==============================] - 1s 231us/step - loss: 4.6538 - mean_absolute_error: 4.6538 - val_loss: 7.2848 - val_mean_absolute_error: 7.2848\n",
      "Epoch 117/500\n",
      "3542/3542 [==============================] - 1s 292us/step - loss: 4.5297 - mean_absolute_error: 4.5297 - val_loss: 6.8989 - val_mean_absolute_error: 6.8989\n",
      "Epoch 118/500\n",
      "3542/3542 [==============================] - 1s 230us/step - loss: 5.3024 - mean_absolute_error: 5.3024 - val_loss: 7.5444 - val_mean_absolute_error: 7.5444\n",
      "Epoch 119/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 5.0789 - mean_absolute_error: 5.0789 - val_loss: 6.8970 - val_mean_absolute_error: 6.8970\n",
      "Epoch 120/500\n",
      "3542/3542 [==============================] - 1s 222us/step - loss: 4.7189 - mean_absolute_error: 4.7189 - val_loss: 6.8545 - val_mean_absolute_error: 6.8545\n",
      "Epoch 121/500\n",
      "3542/3542 [==============================] - 1s 209us/step - loss: 4.7651 - mean_absolute_error: 4.7651 - val_loss: 7.1596 - val_mean_absolute_error: 7.1596\n",
      "Epoch 122/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.5713 - mean_absolute_error: 4.5713 - val_loss: 8.9750 - val_mean_absolute_error: 8.9750\n",
      "Epoch 123/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 4.8541 - mean_absolute_error: 4.8541 - val_loss: 6.6060 - val_mean_absolute_error: 6.6060\n",
      "Epoch 124/500\n",
      "3542/3542 [==============================] - 1s 251us/step - loss: 4.5007 - mean_absolute_error: 4.5007 - val_loss: 8.3630 - val_mean_absolute_error: 8.3630\n",
      "Epoch 125/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.7951 - mean_absolute_error: 4.7951 - val_loss: 6.8053 - val_mean_absolute_error: 6.8053\n",
      "Epoch 126/500\n",
      "3542/3542 [==============================] - 1s 209us/step - loss: 4.5878 - mean_absolute_error: 4.5878 - val_loss: 7.2684 - val_mean_absolute_error: 7.2684\n",
      "Epoch 127/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 5.5919 - mean_absolute_error: 5.5919 - val_loss: 7.5951 - val_mean_absolute_error: 7.5951\n",
      "Epoch 128/500\n",
      "3542/3542 [==============================] - 1s 224us/step - loss: 4.8833 - mean_absolute_error: 4.8833 - val_loss: 9.1528 - val_mean_absolute_error: 9.1528\n",
      "Epoch 129/500\n",
      "3542/3542 [==============================] - 1s 254us/step - loss: 4.9061 - mean_absolute_error: 4.9061 - val_loss: 6.7192 - val_mean_absolute_error: 6.7192\n",
      "Epoch 130/500\n",
      "3542/3542 [==============================] - 1s 257us/step - loss: 4.9218 - mean_absolute_error: 4.9218 - val_loss: 6.9090 - val_mean_absolute_error: 6.9090\n",
      "Epoch 131/500\n",
      "3542/3542 [==============================] - 1s 324us/step - loss: 4.7710 - mean_absolute_error: 4.7710 - val_loss: 7.2036 - val_mean_absolute_error: 7.2036\n",
      "Epoch 132/500\n",
      "3542/3542 [==============================] - 1s 262us/step - loss: 4.1896 - mean_absolute_error: 4.1896 - val_loss: 6.8607 - val_mean_absolute_error: 6.8607\n",
      "Epoch 133/500\n",
      "3542/3542 [==============================] - 1s 262us/step - loss: 4.8009 - mean_absolute_error: 4.8009 - val_loss: 6.9375 - val_mean_absolute_error: 6.9375\n",
      "Epoch 134/500\n",
      "3542/3542 [==============================] - 1s 224us/step - loss: 4.6845 - mean_absolute_error: 4.6845 - val_loss: 6.6910 - val_mean_absolute_error: 6.6910\n",
      "Epoch 135/500\n",
      "3542/3542 [==============================] - 1s 217us/step - loss: 5.0859 - mean_absolute_error: 5.0859 - val_loss: 9.4162 - val_mean_absolute_error: 9.4162\n",
      "Epoch 136/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.6572 - mean_absolute_error: 4.6572 - val_loss: 7.0547 - val_mean_absolute_error: 7.0547\n",
      "Epoch 137/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.5005 - mean_absolute_error: 4.5005 - val_loss: 7.1078 - val_mean_absolute_error: 7.1078\n",
      "Epoch 138/500\n",
      "3542/3542 [==============================] - 1s 197us/step - loss: 5.3127 - mean_absolute_error: 5.3127 - val_loss: 8.0901 - val_mean_absolute_error: 8.0901\n",
      "Epoch 139/500\n",
      "3542/3542 [==============================] - 1s 240us/step - loss: 5.0715 - mean_absolute_error: 5.0715 - val_loss: 8.1842 - val_mean_absolute_error: 8.1842\n",
      "Epoch 140/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 4.8785 - mean_absolute_error: 4.8785 - val_loss: 6.7582 - val_mean_absolute_error: 6.7582\n",
      "Epoch 141/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 4.7833 - mean_absolute_error: 4.7833 - val_loss: 7.5768 - val_mean_absolute_error: 7.5768\n",
      "Epoch 142/500\n",
      "3542/3542 [==============================] - 1s 224us/step - loss: 4.6709 - mean_absolute_error: 4.6709 - val_loss: 7.4133 - val_mean_absolute_error: 7.4133\n",
      "Epoch 143/500\n",
      "3542/3542 [==============================] - 1s 265us/step - loss: 4.5279 - mean_absolute_error: 4.5279 - val_loss: 7.6130 - val_mean_absolute_error: 7.6130\n",
      "Epoch 144/500\n",
      "3542/3542 [==============================] - 1s 234us/step - loss: 5.0497 - mean_absolute_error: 5.0497 - val_loss: 7.3266 - val_mean_absolute_error: 7.3266\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3542/3542 [==============================] - 1s 210us/step - loss: 4.9623 - mean_absolute_error: 4.9623 - val_loss: 7.0376 - val_mean_absolute_error: 7.0376\n",
      "Epoch 146/500\n",
      "3542/3542 [==============================] - 1s 197us/step - loss: 4.5332 - mean_absolute_error: 4.5332 - val_loss: 7.5135 - val_mean_absolute_error: 7.5135\n",
      "Epoch 147/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.7796 - mean_absolute_error: 4.7796 - val_loss: 8.1854 - val_mean_absolute_error: 8.1854\n",
      "Epoch 148/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 5.0952 - mean_absolute_error: 5.0952 - val_loss: 6.7847 - val_mean_absolute_error: 6.7847\n",
      "Epoch 149/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 4.4778 - mean_absolute_error: 4.4778 - val_loss: 6.6713 - val_mean_absolute_error: 6.6713\n",
      "Epoch 150/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 4.4026 - mean_absolute_error: 4.4026 - val_loss: 8.1564 - val_mean_absolute_error: 8.1564\n",
      "Epoch 151/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.8965 - mean_absolute_error: 4.8965 - val_loss: 6.6986 - val_mean_absolute_error: 6.6986\n",
      "Epoch 152/500\n",
      "3542/3542 [==============================] - 1s 202us/step - loss: 4.7834 - mean_absolute_error: 4.7834 - val_loss: 6.7027 - val_mean_absolute_error: 6.7027\n",
      "Epoch 153/500\n",
      "3542/3542 [==============================] - 1s 244us/step - loss: 4.8508 - mean_absolute_error: 4.8508 - val_loss: 6.4795 - val_mean_absolute_error: 6.4795\n",
      "Epoch 154/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 5.0049 - mean_absolute_error: 5.0049 - val_loss: 7.3989 - val_mean_absolute_error: 7.3989\n",
      "Epoch 155/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 5.2641 - mean_absolute_error: 5.2641 - val_loss: 9.8737 - val_mean_absolute_error: 9.8737\n",
      "Epoch 156/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.8110 - mean_absolute_error: 4.8110 - val_loss: 7.2376 - val_mean_absolute_error: 7.2376\n",
      "Epoch 157/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 4.7815 - mean_absolute_error: 4.7815 - val_loss: 7.4080 - val_mean_absolute_error: 7.4080\n",
      "Epoch 158/500\n",
      "3542/3542 [==============================] - 1s 193us/step - loss: 4.5425 - mean_absolute_error: 4.5425 - val_loss: 10.2862 - val_mean_absolute_error: 10.2862\n",
      "Epoch 159/500\n",
      "3542/3542 [==============================] - 1s 235us/step - loss: 4.9864 - mean_absolute_error: 4.9864 - val_loss: 7.6940 - val_mean_absolute_error: 7.6940\n",
      "Epoch 160/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.7655 - mean_absolute_error: 4.7655 - val_loss: 8.1735 - val_mean_absolute_error: 8.1735\n",
      "Epoch 161/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 4.4891 - mean_absolute_error: 4.4891 - val_loss: 6.7135 - val_mean_absolute_error: 6.7135\n",
      "Epoch 162/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 5.2430 - mean_absolute_error: 5.2430 - val_loss: 8.6680 - val_mean_absolute_error: 8.6680\n",
      "Epoch 163/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.8880 - mean_absolute_error: 4.8880 - val_loss: 6.4794 - val_mean_absolute_error: 6.4794\n",
      "Epoch 164/500\n",
      "3542/3542 [==============================] - 1s 193us/step - loss: 4.3481 - mean_absolute_error: 4.3481 - val_loss: 7.6326 - val_mean_absolute_error: 7.6326\n",
      "Epoch 165/500\n",
      "3542/3542 [==============================] - 1s 306us/step - loss: 4.4480 - mean_absolute_error: 4.4480 - val_loss: 6.9690 - val_mean_absolute_error: 6.9690\n",
      "Epoch 166/500\n",
      "3542/3542 [==============================] - 1s 232us/step - loss: 4.4604 - mean_absolute_error: 4.4604 - val_loss: 6.7634 - val_mean_absolute_error: 6.7634\n",
      "Epoch 167/500\n",
      "3542/3542 [==============================] - 1s 257us/step - loss: 4.2707 - mean_absolute_error: 4.2707 - val_loss: 6.5724 - val_mean_absolute_error: 6.5724\n",
      "Epoch 168/500\n",
      "3542/3542 [==============================] - 1s 245us/step - loss: 4.8023 - mean_absolute_error: 4.8023 - val_loss: 6.6774 - val_mean_absolute_error: 6.6774\n",
      "Epoch 169/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 4.4960 - mean_absolute_error: 4.4960 - val_loss: 7.8971 - val_mean_absolute_error: 7.8971\n",
      "Epoch 170/500\n",
      "3542/3542 [==============================] - 1s 216us/step - loss: 4.6994 - mean_absolute_error: 4.6994 - val_loss: 7.3913 - val_mean_absolute_error: 7.3913\n",
      "Epoch 171/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 4.6515 - mean_absolute_error: 4.6515 - val_loss: 6.6513 - val_mean_absolute_error: 6.6513\n",
      "Epoch 172/500\n",
      "3542/3542 [==============================] - 1s 220us/step - loss: 4.6991 - mean_absolute_error: 4.6991 - val_loss: 8.2570 - val_mean_absolute_error: 8.2570\n",
      "Epoch 173/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.7531 - mean_absolute_error: 4.7531 - val_loss: 6.8354 - val_mean_absolute_error: 6.8354\n",
      "Epoch 174/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.6143 - mean_absolute_error: 4.6143 - val_loss: 7.2115 - val_mean_absolute_error: 7.2115\n",
      "Epoch 175/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 4.6785 - mean_absolute_error: 4.6785 - val_loss: 8.6679 - val_mean_absolute_error: 8.6679\n",
      "Epoch 176/500\n",
      "3542/3542 [==============================] - 1s 238us/step - loss: 4.8413 - mean_absolute_error: 4.8413 - val_loss: 7.0561 - val_mean_absolute_error: 7.0561\n",
      "Epoch 177/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 5.0708 - mean_absolute_error: 5.0708 - val_loss: 6.9322 - val_mean_absolute_error: 6.9322\n",
      "Epoch 178/500\n",
      "3542/3542 [==============================] - 1s 187us/step - loss: 4.5031 - mean_absolute_error: 4.5031 - val_loss: 6.8804 - val_mean_absolute_error: 6.8804\n",
      "Epoch 179/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 5.0810 - mean_absolute_error: 5.0810 - val_loss: 6.7995 - val_mean_absolute_error: 6.7995\n",
      "Epoch 180/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 5.2806 - mean_absolute_error: 5.2806 - val_loss: 9.7006 - val_mean_absolute_error: 9.7006\n",
      "Epoch 181/500\n",
      "3542/3542 [==============================] - 1s 199us/step - loss: 4.8945 - mean_absolute_error: 4.8945 - val_loss: 6.8452 - val_mean_absolute_error: 6.8452\n",
      "Epoch 182/500\n",
      "3542/3542 [==============================] - 1s 218us/step - loss: 4.4055 - mean_absolute_error: 4.4055 - val_loss: 7.5611 - val_mean_absolute_error: 7.5611\n",
      "Epoch 183/500\n",
      "3542/3542 [==============================] - 1s 247us/step - loss: 4.5595 - mean_absolute_error: 4.5595 - val_loss: 7.8724 - val_mean_absolute_error: 7.8724\n",
      "Epoch 184/500\n",
      "3542/3542 [==============================] - 1s 237us/step - loss: 4.6665 - mean_absolute_error: 4.6665 - val_loss: 7.2718 - val_mean_absolute_error: 7.2717\n",
      "Epoch 185/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.4677 - mean_absolute_error: 4.4677 - val_loss: 7.6324 - val_mean_absolute_error: 7.6324\n",
      "Epoch 186/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 5.1442 - mean_absolute_error: 5.1442 - val_loss: 7.2613 - val_mean_absolute_error: 7.2613\n",
      "Epoch 187/500\n",
      "3542/3542 [==============================] - 1s 295us/step - loss: 4.3958 - mean_absolute_error: 4.3958 - val_loss: 6.6462 - val_mean_absolute_error: 6.6462\n",
      "Epoch 188/500\n",
      "3542/3542 [==============================] - 1s 194us/step - loss: 4.2526 - mean_absolute_error: 4.2526 - val_loss: 7.3633 - val_mean_absolute_error: 7.3633\n",
      "Epoch 189/500\n",
      "3542/3542 [==============================] - 1s 256us/step - loss: 4.8515 - mean_absolute_error: 4.8515 - val_loss: 6.6623 - val_mean_absolute_error: 6.6623\n",
      "Epoch 190/500\n",
      "3542/3542 [==============================] - 1s 197us/step - loss: 4.6985 - mean_absolute_error: 4.6985 - val_loss: 7.5409 - val_mean_absolute_error: 7.5409\n",
      "Epoch 191/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.8360 - mean_absolute_error: 4.8360 - val_loss: 7.4671 - val_mean_absolute_error: 7.4671\n",
      "Epoch 192/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 4.3224 - mean_absolute_error: 4.3224 - val_loss: 8.0834 - val_mean_absolute_error: 8.0834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.5342 - mean_absolute_error: 4.5342 - val_loss: 7.1899 - val_mean_absolute_error: 7.1899\n",
      "Epoch 194/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.2480 - mean_absolute_error: 4.2480 - val_loss: 7.0357 - val_mean_absolute_error: 7.0357\n",
      "Epoch 195/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.5648 - mean_absolute_error: 4.5648 - val_loss: 8.5716 - val_mean_absolute_error: 8.5716\n",
      "Epoch 196/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 4.8633 - mean_absolute_error: 4.8633 - val_loss: 7.4488 - val_mean_absolute_error: 7.4488\n",
      "Epoch 197/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.5377 - mean_absolute_error: 4.5377 - val_loss: 6.7313 - val_mean_absolute_error: 6.7313\n",
      "Epoch 198/500\n",
      "3542/3542 [==============================] - 1s 256us/step - loss: 4.4499 - mean_absolute_error: 4.4499 - val_loss: 7.0910 - val_mean_absolute_error: 7.0910\n",
      "Epoch 199/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 5.0869 - mean_absolute_error: 5.0869 - val_loss: 6.8853 - val_mean_absolute_error: 6.8853\n",
      "Epoch 200/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 4.3656 - mean_absolute_error: 4.3656 - val_loss: 7.2682 - val_mean_absolute_error: 7.2682\n",
      "Epoch 201/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 5.1230 - mean_absolute_error: 5.1230 - val_loss: 6.9781 - val_mean_absolute_error: 6.9781\n",
      "Epoch 202/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.3190 - mean_absolute_error: 4.3190 - val_loss: 6.7488 - val_mean_absolute_error: 6.7488\n",
      "Epoch 203/500\n",
      "3542/3542 [==============================] - 1s 190us/step - loss: 5.0250 - mean_absolute_error: 5.0250 - val_loss: 6.7435 - val_mean_absolute_error: 6.7435\n",
      "Epoch 204/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 5.1995 - mean_absolute_error: 5.1995 - val_loss: 9.1693 - val_mean_absolute_error: 9.1693\n",
      "Epoch 205/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 4.5367 - mean_absolute_error: 4.5367 - val_loss: 6.9507 - val_mean_absolute_error: 6.9507\n",
      "Epoch 206/500\n",
      "3542/3542 [==============================] - 1s 204us/step - loss: 4.2605 - mean_absolute_error: 4.2605 - val_loss: 6.5301 - val_mean_absolute_error: 6.5301\n",
      "Epoch 207/500\n",
      "3542/3542 [==============================] - 1s 196us/step - loss: 4.4169 - mean_absolute_error: 4.4169 - val_loss: 7.1028 - val_mean_absolute_error: 7.1028\n",
      "Epoch 208/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.1845 - mean_absolute_error: 4.1845 - val_loss: 6.9436 - val_mean_absolute_error: 6.9436\n",
      "Epoch 209/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 4.4952 - mean_absolute_error: 4.4952 - val_loss: 6.6284 - val_mean_absolute_error: 6.6284\n",
      "Epoch 210/500\n",
      "3542/3542 [==============================] - 1s 232us/step - loss: 4.5117 - mean_absolute_error: 4.5117 - val_loss: 7.6362 - val_mean_absolute_error: 7.6362\n",
      "Epoch 211/500\n",
      "3542/3542 [==============================] - 1s 242us/step - loss: 4.3782 - mean_absolute_error: 4.3782 - val_loss: 7.4511 - val_mean_absolute_error: 7.4511\n",
      "Epoch 212/500\n",
      "3542/3542 [==============================] - 1s 191us/step - loss: 4.6201 - mean_absolute_error: 4.6201 - val_loss: 6.7184 - val_mean_absolute_error: 6.7184\n",
      "Epoch 213/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.6645 - mean_absolute_error: 4.6645 - val_loss: 7.6327 - val_mean_absolute_error: 7.6327\n",
      "Epoch 214/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 4.2420 - mean_absolute_error: 4.2420 - val_loss: 6.7241 - val_mean_absolute_error: 6.7241\n",
      "Epoch 215/500\n",
      "3542/3542 [==============================] - 1s 252us/step - loss: 4.2627 - mean_absolute_error: 4.2627 - val_loss: 6.7123 - val_mean_absolute_error: 6.7123\n",
      "Epoch 216/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.8027 - mean_absolute_error: 4.8027 - val_loss: 7.1807 - val_mean_absolute_error: 7.1807\n",
      "Epoch 217/500\n",
      "3542/3542 [==============================] - 1s 300us/step - loss: 4.6869 - mean_absolute_error: 4.6869 - val_loss: 7.1437 - val_mean_absolute_error: 7.1437\n",
      "Epoch 218/500\n",
      "3542/3542 [==============================] - 1s 241us/step - loss: 4.4109 - mean_absolute_error: 4.4109 - val_loss: 7.9544 - val_mean_absolute_error: 7.9544\n",
      "Epoch 219/500\n",
      "3542/3542 [==============================] - 1s 164us/step - loss: 4.8937 - mean_absolute_error: 4.8937 - val_loss: 7.0892 - val_mean_absolute_error: 7.0892\n",
      "Epoch 220/500\n",
      "3542/3542 [==============================] - 1s 200us/step - loss: 4.3623 - mean_absolute_error: 4.3623 - val_loss: 6.6409 - val_mean_absolute_error: 6.6409\n",
      "Epoch 221/500\n",
      "3542/3542 [==============================] - 1s 245us/step - loss: 4.1686 - mean_absolute_error: 4.1686 - val_loss: 6.9072 - val_mean_absolute_error: 6.9072\n",
      "Epoch 222/500\n",
      "3542/3542 [==============================] - 1s 237us/step - loss: 4.3255 - mean_absolute_error: 4.3255 - val_loss: 6.7502 - val_mean_absolute_error: 6.7502\n",
      "Epoch 223/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 4.0166 - mean_absolute_error: 4.0166 - val_loss: 7.0829 - val_mean_absolute_error: 7.0829\n",
      "Epoch 224/500\n",
      "3542/3542 [==============================] - 1s 190us/step - loss: 4.1476 - mean_absolute_error: 4.1476 - val_loss: 7.6200 - val_mean_absolute_error: 7.6200\n",
      "Epoch 225/500\n",
      "3542/3542 [==============================] - 1s 267us/step - loss: 4.2636 - mean_absolute_error: 4.2636 - val_loss: 6.6820 - val_mean_absolute_error: 6.6820\n",
      "Epoch 226/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 4.4676 - mean_absolute_error: 4.4676 - val_loss: 7.3221 - val_mean_absolute_error: 7.3221\n",
      "Epoch 227/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.3336 - mean_absolute_error: 4.3336 - val_loss: 6.6945 - val_mean_absolute_error: 6.6945\n",
      "Epoch 228/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.6320 - mean_absolute_error: 4.6320 - val_loss: 7.1171 - val_mean_absolute_error: 7.1171\n",
      "Epoch 229/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.2844 - mean_absolute_error: 4.2844 - val_loss: 8.2931 - val_mean_absolute_error: 8.2931\n",
      "Epoch 230/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 4.5782 - mean_absolute_error: 4.5782 - val_loss: 7.2820 - val_mean_absolute_error: 7.2820\n",
      "Epoch 231/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.3440 - mean_absolute_error: 4.3440 - val_loss: 7.2828 - val_mean_absolute_error: 7.2828\n",
      "Epoch 232/500\n",
      "3542/3542 [==============================] - 1s 222us/step - loss: 4.1558 - mean_absolute_error: 4.1558 - val_loss: 6.7946 - val_mean_absolute_error: 6.7946\n",
      "Epoch 233/500\n",
      "3542/3542 [==============================] - 1s 237us/step - loss: 4.9816 - mean_absolute_error: 4.9816 - val_loss: 6.8729 - val_mean_absolute_error: 6.8729\n",
      "Epoch 234/500\n",
      "3542/3542 [==============================] - 1s 249us/step - loss: 4.2463 - mean_absolute_error: 4.2463 - val_loss: 7.8244 - val_mean_absolute_error: 7.8244\n",
      "Epoch 235/500\n",
      "3542/3542 [==============================] - 1s 242us/step - loss: 4.2272 - mean_absolute_error: 4.2272 - val_loss: 6.9654 - val_mean_absolute_error: 6.9654\n",
      "Epoch 236/500\n",
      "3542/3542 [==============================] - 1s 291us/step - loss: 4.9126 - mean_absolute_error: 4.9126 - val_loss: 7.9629 - val_mean_absolute_error: 7.9629\n",
      "Epoch 237/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 4.4202 - mean_absolute_error: 4.4202 - val_loss: 6.6833 - val_mean_absolute_error: 6.6833\n",
      "Epoch 238/500\n",
      "3542/3542 [==============================] - 1s 255us/step - loss: 4.1981 - mean_absolute_error: 4.1981 - val_loss: 7.0772 - val_mean_absolute_error: 7.0772\n",
      "Epoch 239/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 5.0093 - mean_absolute_error: 5.0093 - val_loss: 8.0496 - val_mean_absolute_error: 8.0496\n",
      "Epoch 240/500\n",
      "3542/3542 [==============================] - 1s 234us/step - loss: 4.5166 - mean_absolute_error: 4.5166 - val_loss: 7.0556 - val_mean_absolute_error: 7.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "3542/3542 [==============================] - 1s 196us/step - loss: 4.1175 - mean_absolute_error: 4.1175 - val_loss: 6.8275 - val_mean_absolute_error: 6.8275\n",
      "Epoch 242/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.3888 - mean_absolute_error: 4.3888 - val_loss: 6.8921 - val_mean_absolute_error: 6.8921\n",
      "Epoch 243/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.6130 - mean_absolute_error: 4.6130 - val_loss: 7.0249 - val_mean_absolute_error: 7.0249\n",
      "Epoch 244/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.4741 - mean_absolute_error: 4.4741 - val_loss: 7.7758 - val_mean_absolute_error: 7.7758\n",
      "Epoch 245/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 4.4949 - mean_absolute_error: 4.4949 - val_loss: 7.2879 - val_mean_absolute_error: 7.2879\n",
      "Epoch 246/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 4.2417 - mean_absolute_error: 4.2417 - val_loss: 7.1724 - val_mean_absolute_error: 7.1724\n",
      "Epoch 247/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 4.7976 - mean_absolute_error: 4.7976 - val_loss: 6.9604 - val_mean_absolute_error: 6.9604\n",
      "Epoch 248/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.7386 - mean_absolute_error: 4.7386 - val_loss: 6.8565 - val_mean_absolute_error: 6.8565\n",
      "Epoch 249/500\n",
      "3542/3542 [==============================] - 1s 246us/step - loss: 4.4100 - mean_absolute_error: 4.4100 - val_loss: 7.5172 - val_mean_absolute_error: 7.5172\n",
      "Epoch 250/500\n",
      "3542/3542 [==============================] - 1s 240us/step - loss: 4.4470 - mean_absolute_error: 4.4470 - val_loss: 6.9457 - val_mean_absolute_error: 6.9457\n",
      "Epoch 251/500\n",
      "3542/3542 [==============================] - 1s 255us/step - loss: 4.3078 - mean_absolute_error: 4.3078 - val_loss: 6.7944 - val_mean_absolute_error: 6.7944\n",
      "Epoch 252/500\n",
      "3542/3542 [==============================] - 1s 282us/step - loss: 4.1555 - mean_absolute_error: 4.1555 - val_loss: 6.8685 - val_mean_absolute_error: 6.8685\n",
      "Epoch 253/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.3430 - mean_absolute_error: 4.3430 - val_loss: 6.8665 - val_mean_absolute_error: 6.8665\n",
      "Epoch 254/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.7600 - mean_absolute_error: 4.7600 - val_loss: 7.2465 - val_mean_absolute_error: 7.2465\n",
      "Epoch 255/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 4.2947 - mean_absolute_error: 4.2947 - val_loss: 7.0434 - val_mean_absolute_error: 7.0434\n",
      "Epoch 256/500\n",
      "3542/3542 [==============================] - 1s 196us/step - loss: 4.1787 - mean_absolute_error: 4.1787 - val_loss: 7.9112 - val_mean_absolute_error: 7.9112\n",
      "Epoch 257/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 4.4778 - mean_absolute_error: 4.4778 - val_loss: 6.6815 - val_mean_absolute_error: 6.6815\n",
      "Epoch 258/500\n",
      "3542/3542 [==============================] - 1s 277us/step - loss: 4.5461 - mean_absolute_error: 4.5461 - val_loss: 6.9669 - val_mean_absolute_error: 6.9669\n",
      "Epoch 259/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 4.2447 - mean_absolute_error: 4.2447 - val_loss: 6.8980 - val_mean_absolute_error: 6.8980\n",
      "Epoch 260/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 5.0662 - mean_absolute_error: 5.0662 - val_loss: 6.6520 - val_mean_absolute_error: 6.6520\n",
      "Epoch 261/500\n",
      "3542/3542 [==============================] - 1s 317us/step - loss: 4.4038 - mean_absolute_error: 4.4038 - val_loss: 6.7821 - val_mean_absolute_error: 6.7821\n",
      "Epoch 262/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.7364 - mean_absolute_error: 4.7364 - val_loss: 7.0537 - val_mean_absolute_error: 7.0537\n",
      "Epoch 263/500\n",
      "3542/3542 [==============================] - 1s 187us/step - loss: 4.7077 - mean_absolute_error: 4.7077 - val_loss: 6.9160 - val_mean_absolute_error: 6.9160\n",
      "Epoch 264/500\n",
      "3542/3542 [==============================] - 1s 253us/step - loss: 4.2089 - mean_absolute_error: 4.2089 - val_loss: 7.0541 - val_mean_absolute_error: 7.0541\n",
      "Epoch 265/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 3.9966 - mean_absolute_error: 3.9966 - val_loss: 7.2163 - val_mean_absolute_error: 7.2163\n",
      "Epoch 266/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.6159 - mean_absolute_error: 4.6159 - val_loss: 9.1449 - val_mean_absolute_error: 9.1449\n",
      "Epoch 267/500\n",
      "3542/3542 [==============================] - 1s 206us/step - loss: 4.6850 - mean_absolute_error: 4.6850 - val_loss: 7.0373 - val_mean_absolute_error: 7.0373\n",
      "Epoch 268/500\n",
      "3542/3542 [==============================] - 1s 189us/step - loss: 4.2778 - mean_absolute_error: 4.2778 - val_loss: 6.9436 - val_mean_absolute_error: 6.9436\n",
      "Epoch 269/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.3122 - mean_absolute_error: 4.3122 - val_loss: 7.0893 - val_mean_absolute_error: 7.0893\n",
      "Epoch 270/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 4.3737 - mean_absolute_error: 4.3737 - val_loss: 7.4879 - val_mean_absolute_error: 7.4879\n",
      "Epoch 271/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.2357 - mean_absolute_error: 4.2357 - val_loss: 7.1633 - val_mean_absolute_error: 7.1633\n",
      "Epoch 272/500\n",
      "3542/3542 [==============================] - 1s 168us/step - loss: 4.2463 - mean_absolute_error: 4.2463 - val_loss: 6.7578 - val_mean_absolute_error: 6.7578\n",
      "Epoch 273/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 4.3452 - mean_absolute_error: 4.3452 - val_loss: 7.0118 - val_mean_absolute_error: 7.0118\n",
      "Epoch 274/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.2920 - mean_absolute_error: 4.2920 - val_loss: 7.5629 - val_mean_absolute_error: 7.5629\n",
      "Epoch 275/500\n",
      "3542/3542 [==============================] - 1s 217us/step - loss: 5.0175 - mean_absolute_error: 5.0175 - val_loss: 7.2916 - val_mean_absolute_error: 7.2916\n",
      "Epoch 276/500\n",
      "3542/3542 [==============================] - 1s 225us/step - loss: 4.3229 - mean_absolute_error: 4.3229 - val_loss: 7.0428 - val_mean_absolute_error: 7.0428\n",
      "Epoch 277/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.7145 - mean_absolute_error: 4.7145 - val_loss: 7.4480 - val_mean_absolute_error: 7.4480\n",
      "Epoch 278/500\n",
      "3542/3542 [==============================] - 1s 160us/step - loss: 4.3856 - mean_absolute_error: 4.3856 - val_loss: 6.7529 - val_mean_absolute_error: 6.7529\n",
      "Epoch 279/500\n",
      "3542/3542 [==============================] - 1s 160us/step - loss: 4.5282 - mean_absolute_error: 4.5282 - val_loss: 7.0362 - val_mean_absolute_error: 7.0362\n",
      "Epoch 280/500\n",
      "3542/3542 [==============================] - 1s 163us/step - loss: 4.0642 - mean_absolute_error: 4.0642 - val_loss: 8.3970 - val_mean_absolute_error: 8.3970\n",
      "Epoch 281/500\n",
      "3542/3542 [==============================] - 1s 212us/step - loss: 4.7111 - mean_absolute_error: 4.7111 - val_loss: 6.7997 - val_mean_absolute_error: 6.7997\n",
      "Epoch 282/500\n",
      "3542/3542 [==============================] - 1s 216us/step - loss: 4.7550 - mean_absolute_error: 4.7550 - val_loss: 7.1449 - val_mean_absolute_error: 7.1449\n",
      "Epoch 283/500\n",
      "3542/3542 [==============================] - 1s 215us/step - loss: 4.1161 - mean_absolute_error: 4.1161 - val_loss: 6.5939 - val_mean_absolute_error: 6.5939\n",
      "Epoch 284/500\n",
      "3542/3542 [==============================] - 1s 221us/step - loss: 4.3952 - mean_absolute_error: 4.3952 - val_loss: 6.7940 - val_mean_absolute_error: 6.7940\n",
      "Epoch 285/500\n",
      "3542/3542 [==============================] - 1s 278us/step - loss: 3.9426 - mean_absolute_error: 3.9426 - val_loss: 7.3068 - val_mean_absolute_error: 7.3068\n",
      "Epoch 286/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 4.1345 - mean_absolute_error: 4.1345 - val_loss: 6.5670 - val_mean_absolute_error: 6.5670\n",
      "Epoch 287/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 3.9261 - mean_absolute_error: 3.9261 - val_loss: 7.1755 - val_mean_absolute_error: 7.1755\n",
      "Epoch 288/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 4.1114 - mean_absolute_error: 4.1114 - val_loss: 6.8427 - val_mean_absolute_error: 6.8427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.2660 - mean_absolute_error: 4.2660 - val_loss: 6.9511 - val_mean_absolute_error: 6.9511\n",
      "Epoch 290/500\n",
      "3542/3542 [==============================] - 1s 242us/step - loss: 4.1331 - mean_absolute_error: 4.1331 - val_loss: 10.2688 - val_mean_absolute_error: 10.2688\n",
      "Epoch 291/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 4.4478 - mean_absolute_error: 4.4478 - val_loss: 6.9244 - val_mean_absolute_error: 6.9244\n",
      "Epoch 292/500\n",
      "3542/3542 [==============================] - 1s 250us/step - loss: 3.9642 - mean_absolute_error: 3.9642 - val_loss: 7.0260 - val_mean_absolute_error: 7.0260\n",
      "Epoch 293/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 4.0996 - mean_absolute_error: 4.0996 - val_loss: 6.9419 - val_mean_absolute_error: 6.9419\n",
      "Epoch 294/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 4.3117 - mean_absolute_error: 4.3117 - val_loss: 7.1236 - val_mean_absolute_error: 7.1236\n",
      "Epoch 295/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.2279 - mean_absolute_error: 4.2279 - val_loss: 6.7076 - val_mean_absolute_error: 6.7076\n",
      "Epoch 296/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 4.6908 - mean_absolute_error: 4.6907 - val_loss: 7.9440 - val_mean_absolute_error: 7.9440\n",
      "Epoch 297/500\n",
      "3542/3542 [==============================] - 1s 344us/step - loss: 4.2188 - mean_absolute_error: 4.2188 - val_loss: 7.4652 - val_mean_absolute_error: 7.4652\n",
      "Epoch 298/500\n",
      "3542/3542 [==============================] - 1s 237us/step - loss: 4.4293 - mean_absolute_error: 4.4293 - val_loss: 7.2807 - val_mean_absolute_error: 7.2807\n",
      "Epoch 299/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.6719 - mean_absolute_error: 4.6719 - val_loss: 8.0427 - val_mean_absolute_error: 8.0427\n",
      "Epoch 300/500\n",
      "3542/3542 [==============================] - 1s 177us/step - loss: 4.1643 - mean_absolute_error: 4.1643 - val_loss: 6.8558 - val_mean_absolute_error: 6.8558\n",
      "Epoch 301/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 4.6270 - mean_absolute_error: 4.6270 - val_loss: 7.1481 - val_mean_absolute_error: 7.1481\n",
      "Epoch 302/500\n",
      "3542/3542 [==============================] - 1s 163us/step - loss: 4.3187 - mean_absolute_error: 4.3187 - val_loss: 6.8414 - val_mean_absolute_error: 6.8414\n",
      "Epoch 303/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 3.9916 - mean_absolute_error: 3.9917 - val_loss: 6.7637 - val_mean_absolute_error: 6.7637\n",
      "Epoch 304/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.1829 - mean_absolute_error: 4.1829 - val_loss: 7.6764 - val_mean_absolute_error: 7.6764\n",
      "Epoch 305/500\n",
      "3542/3542 [==============================] - 1s 168us/step - loss: 4.3531 - mean_absolute_error: 4.3531 - val_loss: 6.9461 - val_mean_absolute_error: 6.9461\n",
      "Epoch 306/500\n",
      "3542/3542 [==============================] - 1s 197us/step - loss: 4.0822 - mean_absolute_error: 4.0822 - val_loss: 8.6056 - val_mean_absolute_error: 8.6056\n",
      "Epoch 307/500\n",
      "3542/3542 [==============================] - 1s 231us/step - loss: 4.0598 - mean_absolute_error: 4.0598 - val_loss: 7.0012 - val_mean_absolute_error: 7.0012\n",
      "Epoch 308/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.4590 - mean_absolute_error: 4.4590 - val_loss: 6.5783 - val_mean_absolute_error: 6.5783\n",
      "Epoch 309/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 4.0254 - mean_absolute_error: 4.0254 - val_loss: 6.8647 - val_mean_absolute_error: 6.8648\n",
      "Epoch 310/500\n",
      "3542/3542 [==============================] - 1s 169us/step - loss: 4.1557 - mean_absolute_error: 4.1557 - val_loss: 6.8094 - val_mean_absolute_error: 6.8094\n",
      "Epoch 311/500\n",
      "3542/3542 [==============================] - 1s 165us/step - loss: 4.4012 - mean_absolute_error: 4.4012 - val_loss: 7.5385 - val_mean_absolute_error: 7.5385\n",
      "Epoch 312/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 4.2019 - mean_absolute_error: 4.2019 - val_loss: 7.9823 - val_mean_absolute_error: 7.9823\n",
      "Epoch 313/500\n",
      "3542/3542 [==============================] - 1s 170us/step - loss: 4.5316 - mean_absolute_error: 4.5316 - val_loss: 9.2044 - val_mean_absolute_error: 9.2044\n",
      "Epoch 314/500\n",
      "3542/3542 [==============================] - 1s 169us/step - loss: 4.3510 - mean_absolute_error: 4.3510 - val_loss: 7.3171 - val_mean_absolute_error: 7.3171\n",
      "Epoch 315/500\n",
      "3542/3542 [==============================] - 1s 166us/step - loss: 4.4780 - mean_absolute_error: 4.4780 - val_loss: 7.5266 - val_mean_absolute_error: 7.5266\n",
      "Epoch 316/500\n",
      "3542/3542 [==============================] - 1s 166us/step - loss: 3.9050 - mean_absolute_error: 3.9050 - val_loss: 6.8168 - val_mean_absolute_error: 6.8168\n",
      "Epoch 317/500\n",
      "3542/3542 [==============================] - 1s 166us/step - loss: 4.5198 - mean_absolute_error: 4.5198 - val_loss: 7.5082 - val_mean_absolute_error: 7.5082\n",
      "Epoch 318/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.1436 - mean_absolute_error: 4.1436 - val_loss: 8.6412 - val_mean_absolute_error: 8.6412\n",
      "Epoch 319/500\n",
      "3542/3542 [==============================] - 1s 265us/step - loss: 4.4972 - mean_absolute_error: 4.4972 - val_loss: 7.6886 - val_mean_absolute_error: 7.6886\n",
      "Epoch 320/500\n",
      "3542/3542 [==============================] - 1s 318us/step - loss: 3.9346 - mean_absolute_error: 3.9346 - val_loss: 7.4021 - val_mean_absolute_error: 7.4021\n",
      "Epoch 321/500\n",
      "3542/3542 [==============================] - 1s 234us/step - loss: 4.2035 - mean_absolute_error: 4.2035 - val_loss: 7.7217 - val_mean_absolute_error: 7.7217\n",
      "Epoch 322/500\n",
      "3542/3542 [==============================] - 1s 217us/step - loss: 4.2669 - mean_absolute_error: 4.2669 - val_loss: 6.9486 - val_mean_absolute_error: 6.9486\n",
      "Epoch 323/500\n",
      "3542/3542 [==============================] - 1s 216us/step - loss: 4.1487 - mean_absolute_error: 4.1487 - val_loss: 9.5879 - val_mean_absolute_error: 9.5879\n",
      "Epoch 324/500\n",
      "3542/3542 [==============================] - 1s 215us/step - loss: 4.3113 - mean_absolute_error: 4.3113 - val_loss: 6.8182 - val_mean_absolute_error: 6.8182\n",
      "Epoch 325/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.1912 - mean_absolute_error: 4.1912 - val_loss: 7.0435 - val_mean_absolute_error: 7.0435\n",
      "Epoch 326/500\n",
      "3542/3542 [==============================] - 1s 200us/step - loss: 4.0595 - mean_absolute_error: 4.0595 - val_loss: 7.0023 - val_mean_absolute_error: 7.0023\n",
      "Epoch 327/500\n",
      "3542/3542 [==============================] - 1s 229us/step - loss: 3.9505 - mean_absolute_error: 3.9505 - val_loss: 7.0650 - val_mean_absolute_error: 7.0650\n",
      "Epoch 328/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 4.4553 - mean_absolute_error: 4.4553 - val_loss: 8.9985 - val_mean_absolute_error: 8.9985\n",
      "Epoch 329/500\n",
      "3542/3542 [==============================] - 1s 200us/step - loss: 3.9436 - mean_absolute_error: 3.9436 - val_loss: 7.3463 - val_mean_absolute_error: 7.3463\n",
      "Epoch 330/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.1343 - mean_absolute_error: 4.1343 - val_loss: 7.5745 - val_mean_absolute_error: 7.5745\n",
      "Epoch 331/500\n",
      "3542/3542 [==============================] - 1s 222us/step - loss: 4.1773 - mean_absolute_error: 4.1773 - val_loss: 6.9227 - val_mean_absolute_error: 6.9227\n",
      "Epoch 332/500\n",
      "3542/3542 [==============================] - 1s 221us/step - loss: 4.2461 - mean_absolute_error: 4.2461 - val_loss: 8.9714 - val_mean_absolute_error: 8.9714\n",
      "Epoch 333/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 4.2803 - mean_absolute_error: 4.2803 - val_loss: 7.0983 - val_mean_absolute_error: 7.0983\n",
      "Epoch 334/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.0763 - mean_absolute_error: 4.0763 - val_loss: 7.0550 - val_mean_absolute_error: 7.0550\n",
      "Epoch 335/500\n",
      "3542/3542 [==============================] - 1s 226us/step - loss: 4.3407 - mean_absolute_error: 4.3407 - val_loss: 7.0699 - val_mean_absolute_error: 7.0699\n",
      "Epoch 336/500\n",
      "3542/3542 [==============================] - 1s 275us/step - loss: 4.0142 - mean_absolute_error: 4.0142 - val_loss: 6.8514 - val_mean_absolute_error: 6.8514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 4.1863 - mean_absolute_error: 4.1863 - val_loss: 6.7940 - val_mean_absolute_error: 6.7940\n",
      "Epoch 338/500\n",
      "3542/3542 [==============================] - 1s 252us/step - loss: 4.0902 - mean_absolute_error: 4.0902 - val_loss: 6.9968 - val_mean_absolute_error: 6.9968\n",
      "Epoch 339/500\n",
      "3542/3542 [==============================] - 1s 250us/step - loss: 4.1140 - mean_absolute_error: 4.1140 - val_loss: 8.1458 - val_mean_absolute_error: 8.1458\n",
      "Epoch 340/500\n",
      "3542/3542 [==============================] - 1s 270us/step - loss: 4.5802 - mean_absolute_error: 4.5802 - val_loss: 7.0851 - val_mean_absolute_error: 7.0851\n",
      "Epoch 341/500\n",
      "3542/3542 [==============================] - 1s 245us/step - loss: 4.1185 - mean_absolute_error: 4.1185 - val_loss: 6.8348 - val_mean_absolute_error: 6.8348\n",
      "Epoch 342/500\n",
      "3542/3542 [==============================] - 1s 232us/step - loss: 3.9946 - mean_absolute_error: 3.9946 - val_loss: 6.8534 - val_mean_absolute_error: 6.8534\n",
      "Epoch 343/500\n",
      "3542/3542 [==============================] - 1s 240us/step - loss: 4.0745 - mean_absolute_error: 4.0745 - val_loss: 6.7090 - val_mean_absolute_error: 6.7090\n",
      "Epoch 344/500\n",
      "3542/3542 [==============================] - 1s 255us/step - loss: 4.0038 - mean_absolute_error: 4.0038 - val_loss: 7.3249 - val_mean_absolute_error: 7.3249\n",
      "Epoch 345/500\n",
      "3542/3542 [==============================] - 1s 209us/step - loss: 4.0180 - mean_absolute_error: 4.0180 - val_loss: 6.9849 - val_mean_absolute_error: 6.9849\n",
      "Epoch 346/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.6442 - mean_absolute_error: 4.6442 - val_loss: 8.0127 - val_mean_absolute_error: 8.0127\n",
      "Epoch 347/500\n",
      "3542/3542 [==============================] - 1s 239us/step - loss: 4.1359 - mean_absolute_error: 4.1359 - val_loss: 6.6270 - val_mean_absolute_error: 6.6270\n",
      "Epoch 348/500\n",
      "3542/3542 [==============================] - 1s 194us/step - loss: 4.2758 - mean_absolute_error: 4.2758 - val_loss: 7.4617 - val_mean_absolute_error: 7.4617\n",
      "Epoch 349/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 4.2081 - mean_absolute_error: 4.2081 - val_loss: 6.6585 - val_mean_absolute_error: 6.6585\n",
      "Epoch 350/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 4.1415 - mean_absolute_error: 4.1415 - val_loss: 8.2026 - val_mean_absolute_error: 8.2026\n",
      "Epoch 351/500\n",
      "3542/3542 [==============================] - 1s 220us/step - loss: 4.1477 - mean_absolute_error: 4.1477 - val_loss: 7.6376 - val_mean_absolute_error: 7.6376\n",
      "Epoch 352/500\n",
      "3542/3542 [==============================] - 1s 196us/step - loss: 4.5144 - mean_absolute_error: 4.5144 - val_loss: 6.7144 - val_mean_absolute_error: 6.7144\n",
      "Epoch 353/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 4.0808 - mean_absolute_error: 4.0808 - val_loss: 9.4422 - val_mean_absolute_error: 9.4422\n",
      "Epoch 354/500\n",
      "3542/3542 [==============================] - 1s 243us/step - loss: 4.0260 - mean_absolute_error: 4.0260 - val_loss: 6.7647 - val_mean_absolute_error: 6.7647\n",
      "Epoch 355/500\n",
      "3542/3542 [==============================] - 1s 204us/step - loss: 3.7935 - mean_absolute_error: 3.7935 - val_loss: 7.2497 - val_mean_absolute_error: 7.2497\n",
      "Epoch 356/500\n",
      "3542/3542 [==============================] - 1s 197us/step - loss: 4.5696 - mean_absolute_error: 4.5696 - val_loss: 7.1741 - val_mean_absolute_error: 7.1741\n",
      "Epoch 357/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 4.1222 - mean_absolute_error: 4.1222 - val_loss: 7.9355 - val_mean_absolute_error: 7.9355\n",
      "Epoch 358/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.1805 - mean_absolute_error: 4.1805 - val_loss: 7.0637 - val_mean_absolute_error: 7.0637\n",
      "Epoch 359/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 3.9649 - mean_absolute_error: 3.9648 - val_loss: 7.6587 - val_mean_absolute_error: 7.6587\n",
      "Epoch 360/500\n",
      "3542/3542 [==============================] - 1s 194us/step - loss: 4.0500 - mean_absolute_error: 4.0500 - val_loss: 6.9101 - val_mean_absolute_error: 6.9101\n",
      "Epoch 361/500\n",
      "3542/3542 [==============================] - 1s 226us/step - loss: 4.5020 - mean_absolute_error: 4.5020 - val_loss: 6.6968 - val_mean_absolute_error: 6.6968\n",
      "Epoch 362/500\n",
      "3542/3542 [==============================] - 1s 246us/step - loss: 4.0555 - mean_absolute_error: 4.0555 - val_loss: 6.6459 - val_mean_absolute_error: 6.6459\n",
      "Epoch 363/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 3.8402 - mean_absolute_error: 3.8402 - val_loss: 7.2667 - val_mean_absolute_error: 7.2667\n",
      "Epoch 364/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.1697 - mean_absolute_error: 4.1697 - val_loss: 6.7574 - val_mean_absolute_error: 6.7574\n",
      "Epoch 365/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 3.9893 - mean_absolute_error: 3.9893 - val_loss: 7.2796 - val_mean_absolute_error: 7.2796\n",
      "Epoch 366/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 4.2480 - mean_absolute_error: 4.2480 - val_loss: 7.4863 - val_mean_absolute_error: 7.4863\n",
      "Epoch 367/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 4.2767 - mean_absolute_error: 4.2767 - val_loss: 9.4211 - val_mean_absolute_error: 9.4211\n",
      "Epoch 368/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 4.7010 - mean_absolute_error: 4.7010 - val_loss: 7.3151 - val_mean_absolute_error: 7.3151\n",
      "Epoch 369/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.5344 - mean_absolute_error: 4.5344 - val_loss: 6.8692 - val_mean_absolute_error: 6.8692\n",
      "Epoch 370/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 3.9073 - mean_absolute_error: 3.9073 - val_loss: 6.8011 - val_mean_absolute_error: 6.8011\n",
      "Epoch 371/500\n",
      "3542/3542 [==============================] - 1s 171us/step - loss: 3.8191 - mean_absolute_error: 3.8191 - val_loss: 6.7733 - val_mean_absolute_error: 6.7733\n",
      "Epoch 372/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 4.3761 - mean_absolute_error: 4.3761 - val_loss: 7.0282 - val_mean_absolute_error: 7.0282\n",
      "Epoch 373/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 3.8922 - mean_absolute_error: 3.8922 - val_loss: 6.7932 - val_mean_absolute_error: 6.7932\n",
      "Epoch 374/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 4.4742 - mean_absolute_error: 4.4742 - val_loss: 8.9292 - val_mean_absolute_error: 8.9292\n",
      "Epoch 375/500\n",
      "3542/3542 [==============================] - 1s 174us/step - loss: 4.3334 - mean_absolute_error: 4.3334 - val_loss: 6.7601 - val_mean_absolute_error: 6.7601\n",
      "Epoch 376/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.0270 - mean_absolute_error: 4.0270 - val_loss: 6.6494 - val_mean_absolute_error: 6.6494\n",
      "Epoch 377/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 3.9848 - mean_absolute_error: 3.9848 - val_loss: 7.1041 - val_mean_absolute_error: 7.1041\n",
      "Epoch 378/500\n",
      "3542/3542 [==============================] - 1s 210us/step - loss: 3.9494 - mean_absolute_error: 3.9494 - val_loss: 6.8077 - val_mean_absolute_error: 6.8077\n",
      "Epoch 379/500\n",
      "3542/3542 [==============================] - 1s 241us/step - loss: 3.7710 - mean_absolute_error: 3.7710 - val_loss: 6.8901 - val_mean_absolute_error: 6.8901\n",
      "Epoch 380/500\n",
      "3542/3542 [==============================] - 1s 292us/step - loss: 3.8220 - mean_absolute_error: 3.8220 - val_loss: 6.9003 - val_mean_absolute_error: 6.9003\n",
      "Epoch 381/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 3.9247 - mean_absolute_error: 3.9247 - val_loss: 6.8939 - val_mean_absolute_error: 6.8939\n",
      "Epoch 382/500\n",
      "3542/3542 [==============================] - 1s 247us/step - loss: 4.1318 - mean_absolute_error: 4.1318 - val_loss: 6.7380 - val_mean_absolute_error: 6.7380\n",
      "Epoch 383/500\n",
      "3542/3542 [==============================] - 1s 281us/step - loss: 4.0514 - mean_absolute_error: 4.0514 - val_loss: 6.8549 - val_mean_absolute_error: 6.8549\n",
      "Epoch 384/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.0605 - mean_absolute_error: 4.0605 - val_loss: 7.3480 - val_mean_absolute_error: 7.3480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      "3542/3542 [==============================] - 1s 183us/step - loss: 3.9746 - mean_absolute_error: 3.9746 - val_loss: 7.2311 - val_mean_absolute_error: 7.2311\n",
      "Epoch 386/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 4.2004 - mean_absolute_error: 4.2004 - val_loss: 7.7244 - val_mean_absolute_error: 7.7244\n",
      "Epoch 387/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.5726 - mean_absolute_error: 4.5726 - val_loss: 7.1419 - val_mean_absolute_error: 7.1419\n",
      "Epoch 388/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 4.1304 - mean_absolute_error: 4.1304 - val_loss: 7.0004 - val_mean_absolute_error: 7.0004\n",
      "Epoch 389/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 3.9176 - mean_absolute_error: 3.9176 - val_loss: 6.7645 - val_mean_absolute_error: 6.7645\n",
      "Epoch 390/500\n",
      "3542/3542 [==============================] - 1s 228us/step - loss: 4.5327 - mean_absolute_error: 4.5327 - val_loss: 7.0129 - val_mean_absolute_error: 7.0129\n",
      "Epoch 391/500\n",
      "3542/3542 [==============================] - 1s 244us/step - loss: 4.1112 - mean_absolute_error: 4.1112 - val_loss: 7.1749 - val_mean_absolute_error: 7.1749\n",
      "Epoch 392/500\n",
      "3542/3542 [==============================] - 1s 248us/step - loss: 3.7737 - mean_absolute_error: 3.7737 - val_loss: 8.1247 - val_mean_absolute_error: 8.1247\n",
      "Epoch 393/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.5791 - mean_absolute_error: 4.5791 - val_loss: 7.2359 - val_mean_absolute_error: 7.2359\n",
      "Epoch 394/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 4.0040 - mean_absolute_error: 4.0040 - val_loss: 6.9305 - val_mean_absolute_error: 6.9305\n",
      "Epoch 395/500\n",
      "3542/3542 [==============================] - 1s 222us/step - loss: 4.3656 - mean_absolute_error: 4.3656 - val_loss: 6.9043 - val_mean_absolute_error: 6.9043\n",
      "Epoch 396/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 3.8671 - mean_absolute_error: 3.8671 - val_loss: 6.9832 - val_mean_absolute_error: 6.9832\n",
      "Epoch 397/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.7195 - mean_absolute_error: 4.7195 - val_loss: 8.1512 - val_mean_absolute_error: 8.1512\n",
      "Epoch 398/500\n",
      "3542/3542 [==============================] - 1s 237us/step - loss: 3.9450 - mean_absolute_error: 3.9450 - val_loss: 7.1284 - val_mean_absolute_error: 7.1284\n",
      "Epoch 399/500\n",
      "3542/3542 [==============================] - 1s 267us/step - loss: 4.0551 - mean_absolute_error: 4.0551 - val_loss: 7.7287 - val_mean_absolute_error: 7.7287\n",
      "Epoch 400/500\n",
      "3542/3542 [==============================] - 1s 229us/step - loss: 4.0441 - mean_absolute_error: 4.0441 - val_loss: 7.0322 - val_mean_absolute_error: 7.0322\n",
      "Epoch 401/500\n",
      "3542/3542 [==============================] - 1s 194us/step - loss: 4.2840 - mean_absolute_error: 4.2840 - val_loss: 8.0425 - val_mean_absolute_error: 8.0425\n",
      "Epoch 402/500\n",
      "3542/3542 [==============================] - 1s 280us/step - loss: 4.0731 - mean_absolute_error: 4.0731 - val_loss: 7.0813 - val_mean_absolute_error: 7.0813\n",
      "Epoch 403/500\n",
      "3542/3542 [==============================] - 1s 248us/step - loss: 3.7232 - mean_absolute_error: 3.7232 - val_loss: 6.9504 - val_mean_absolute_error: 6.9504\n",
      "Epoch 404/500\n",
      "3542/3542 [==============================] - 1s 238us/step - loss: 4.1827 - mean_absolute_error: 4.1827 - val_loss: 7.0743 - val_mean_absolute_error: 7.0743\n",
      "Epoch 405/500\n",
      "3542/3542 [==============================] - 1s 231us/step - loss: 3.8397 - mean_absolute_error: 3.8397 - val_loss: 7.1515 - val_mean_absolute_error: 7.1515\n",
      "Epoch 406/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 3.8548 - mean_absolute_error: 3.8548 - val_loss: 7.2227 - val_mean_absolute_error: 7.2227\n",
      "Epoch 407/500\n",
      "3542/3542 [==============================] - 1s 238us/step - loss: 4.0298 - mean_absolute_error: 4.0298 - val_loss: 6.9099 - val_mean_absolute_error: 6.9099\n",
      "Epoch 408/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.1167 - mean_absolute_error: 4.1167 - val_loss: 9.0966 - val_mean_absolute_error: 9.0966\n",
      "Epoch 409/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 4.1680 - mean_absolute_error: 4.1680 - val_loss: 6.9751 - val_mean_absolute_error: 6.9751\n",
      "Epoch 410/500\n",
      "3542/3542 [==============================] - 1s 191us/step - loss: 4.1382 - mean_absolute_error: 4.1382 - val_loss: 8.8876 - val_mean_absolute_error: 8.8876\n",
      "Epoch 411/500\n",
      "3542/3542 [==============================] - 1s 226us/step - loss: 3.9275 - mean_absolute_error: 3.9275 - val_loss: 6.7093 - val_mean_absolute_error: 6.7093\n",
      "Epoch 412/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 3.7990 - mean_absolute_error: 3.7990 - val_loss: 6.9253 - val_mean_absolute_error: 6.9253\n",
      "Epoch 413/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.0336 - mean_absolute_error: 4.0336 - val_loss: 6.9942 - val_mean_absolute_error: 6.9942\n",
      "Epoch 414/500\n",
      "3542/3542 [==============================] - 1s 258us/step - loss: 3.8117 - mean_absolute_error: 3.8117 - val_loss: 7.0486 - val_mean_absolute_error: 7.0486\n",
      "Epoch 415/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 4.1230 - mean_absolute_error: 4.1230 - val_loss: 7.2974 - val_mean_absolute_error: 7.2974\n",
      "Epoch 416/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 3.7323 - mean_absolute_error: 3.7323 - val_loss: 6.7162 - val_mean_absolute_error: 6.7162\n",
      "Epoch 417/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 3.6495 - mean_absolute_error: 3.6495 - val_loss: 6.7593 - val_mean_absolute_error: 6.7593\n",
      "Epoch 418/500\n",
      "3542/3542 [==============================] - 1s 195us/step - loss: 4.4434 - mean_absolute_error: 4.4434 - val_loss: 6.7678 - val_mean_absolute_error: 6.7678\n",
      "Epoch 419/500\n",
      "3542/3542 [==============================] - 1s 228us/step - loss: 3.7808 - mean_absolute_error: 3.7808 - val_loss: 7.0561 - val_mean_absolute_error: 7.0561\n",
      "Epoch 420/500\n",
      "3542/3542 [==============================] - 1s 215us/step - loss: 4.0558 - mean_absolute_error: 4.0558 - val_loss: 6.8119 - val_mean_absolute_error: 6.8119\n",
      "Epoch 421/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 3.8704 - mean_absolute_error: 3.8704 - val_loss: 6.8527 - val_mean_absolute_error: 6.8527\n",
      "Epoch 422/500\n",
      "3542/3542 [==============================] - 1s 198us/step - loss: 3.9801 - mean_absolute_error: 3.9801 - val_loss: 7.0747 - val_mean_absolute_error: 7.0747\n",
      "Epoch 423/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 3.7870 - mean_absolute_error: 3.7870 - val_loss: 6.8540 - val_mean_absolute_error: 6.8540\n",
      "Epoch 424/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 3.8805 - mean_absolute_error: 3.8805 - val_loss: 6.9121 - val_mean_absolute_error: 6.9121\n",
      "Epoch 425/500\n",
      "3542/3542 [==============================] - 1s 280us/step - loss: 4.0897 - mean_absolute_error: 4.0897 - val_loss: 7.0328 - val_mean_absolute_error: 7.0328\n",
      "Epoch 426/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.3886 - mean_absolute_error: 4.3886 - val_loss: 7.1255 - val_mean_absolute_error: 7.1255\n",
      "Epoch 427/500\n",
      "3542/3542 [==============================] - 1s 187us/step - loss: 4.0725 - mean_absolute_error: 4.0725 - val_loss: 7.3985 - val_mean_absolute_error: 7.3985\n",
      "Epoch 428/500\n",
      "3542/3542 [==============================] - 1s 218us/step - loss: 3.5784 - mean_absolute_error: 3.5784 - val_loss: 7.1724 - val_mean_absolute_error: 7.1724\n",
      "Epoch 429/500\n",
      "3542/3542 [==============================] - 1s 199us/step - loss: 3.9701 - mean_absolute_error: 3.9701 - val_loss: 7.9229 - val_mean_absolute_error: 7.9229\n",
      "Epoch 430/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 3.7917 - mean_absolute_error: 3.7917 - val_loss: 6.7268 - val_mean_absolute_error: 6.7268\n",
      "Epoch 431/500\n",
      "3542/3542 [==============================] - 1s 181us/step - loss: 4.2672 - mean_absolute_error: 4.2672 - val_loss: 7.2025 - val_mean_absolute_error: 7.2025\n",
      "Epoch 432/500\n",
      "3542/3542 [==============================] - 1s 191us/step - loss: 3.7344 - mean_absolute_error: 3.7344 - val_loss: 7.0884 - val_mean_absolute_error: 7.0884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/500\n",
      "3542/3542 [==============================] - 1s 177us/step - loss: 3.9585 - mean_absolute_error: 3.9585 - val_loss: 7.5953 - val_mean_absolute_error: 7.5953\n",
      "Epoch 434/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 4.1197 - mean_absolute_error: 4.1197 - val_loss: 7.1308 - val_mean_absolute_error: 7.1308\n",
      "Epoch 435/500\n",
      "3542/3542 [==============================] - 1s 215us/step - loss: 3.7016 - mean_absolute_error: 3.7016 - val_loss: 7.4632 - val_mean_absolute_error: 7.4632\n",
      "Epoch 436/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 3.4678 - mean_absolute_error: 3.4678 - val_loss: 6.8381 - val_mean_absolute_error: 6.8381\n",
      "Epoch 437/500\n",
      "3542/3542 [==============================] - 1s 178us/step - loss: 3.8563 - mean_absolute_error: 3.8563 - val_loss: 7.3837 - val_mean_absolute_error: 7.3837\n",
      "Epoch 438/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 3.7891 - mean_absolute_error: 3.7891 - val_loss: 8.0348 - val_mean_absolute_error: 8.0348\n",
      "Epoch 439/500\n",
      "3542/3542 [==============================] - 1s 182us/step - loss: 3.9371 - mean_absolute_error: 3.9371 - val_loss: 6.7693 - val_mean_absolute_error: 6.7693\n",
      "Epoch 440/500\n",
      "3542/3542 [==============================] - 1s 248us/step - loss: 3.9448 - mean_absolute_error: 3.9448 - val_loss: 6.8119 - val_mean_absolute_error: 6.8119\n",
      "Epoch 441/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 3.7903 - mean_absolute_error: 3.7903 - val_loss: 6.9397 - val_mean_absolute_error: 6.9397\n",
      "Epoch 442/500\n",
      "3542/3542 [==============================] - 1s 201us/step - loss: 3.6372 - mean_absolute_error: 3.6372 - val_loss: 6.8969 - val_mean_absolute_error: 6.8969\n",
      "Epoch 443/500\n",
      "3542/3542 [==============================] - 1s 186us/step - loss: 4.1795 - mean_absolute_error: 4.1795 - val_loss: 7.3834 - val_mean_absolute_error: 7.3834\n",
      "Epoch 444/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 3.6714 - mean_absolute_error: 3.6714 - val_loss: 6.9443 - val_mean_absolute_error: 6.9443\n",
      "Epoch 445/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 4.2991 - mean_absolute_error: 4.2991 - val_loss: 7.2173 - val_mean_absolute_error: 7.2173\n",
      "Epoch 446/500\n",
      "3542/3542 [==============================] - 1s 192us/step - loss: 3.9583 - mean_absolute_error: 3.9583 - val_loss: 6.9527 - val_mean_absolute_error: 6.9527\n",
      "Epoch 447/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 3.8746 - mean_absolute_error: 3.8746 - val_loss: 6.8263 - val_mean_absolute_error: 6.8263\n",
      "Epoch 448/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 3.7753 - mean_absolute_error: 3.7753 - val_loss: 6.6652 - val_mean_absolute_error: 6.6652\n",
      "Epoch 449/500\n",
      "3542/3542 [==============================] - 1s 173us/step - loss: 3.6366 - mean_absolute_error: 3.6366 - val_loss: 6.9613 - val_mean_absolute_error: 6.9613\n",
      "Epoch 450/500\n",
      "3542/3542 [==============================] - 1s 224us/step - loss: 3.9113 - mean_absolute_error: 3.9113 - val_loss: 6.8052 - val_mean_absolute_error: 6.8052\n",
      "Epoch 451/500\n",
      "3542/3542 [==============================] - 1s 234us/step - loss: 3.6843 - mean_absolute_error: 3.6843 - val_loss: 9.1229 - val_mean_absolute_error: 9.1229\n",
      "Epoch 452/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 4.2655 - mean_absolute_error: 4.2655 - val_loss: 7.1057 - val_mean_absolute_error: 7.1057\n",
      "Epoch 453/500\n",
      "3542/3542 [==============================] - 1s 203us/step - loss: 3.9380 - mean_absolute_error: 3.9380 - val_loss: 7.1529 - val_mean_absolute_error: 7.1529\n",
      "Epoch 454/500\n",
      "3542/3542 [==============================] - 1s 196us/step - loss: 3.7690 - mean_absolute_error: 3.7690 - val_loss: 6.7644 - val_mean_absolute_error: 6.7644\n",
      "Epoch 455/500\n",
      "3542/3542 [==============================] - 1s 179us/step - loss: 3.7568 - mean_absolute_error: 3.7568 - val_loss: 6.7753 - val_mean_absolute_error: 6.7753\n",
      "Epoch 456/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 3.8169 - mean_absolute_error: 3.8169 - val_loss: 7.1009 - val_mean_absolute_error: 7.1009\n",
      "Epoch 457/500\n",
      "3542/3542 [==============================] - 1s 280us/step - loss: 3.6127 - mean_absolute_error: 3.6127 - val_loss: 7.1763 - val_mean_absolute_error: 7.1763\n",
      "Epoch 458/500\n",
      "3542/3542 [==============================] - 1s 273us/step - loss: 3.8443 - mean_absolute_error: 3.8443 - val_loss: 8.0104 - val_mean_absolute_error: 8.0104\n",
      "Epoch 459/500\n",
      "3542/3542 [==============================] - 1s 193us/step - loss: 3.7526 - mean_absolute_error: 3.7526 - val_loss: 6.6700 - val_mean_absolute_error: 6.6700\n",
      "Epoch 460/500\n",
      "3542/3542 [==============================] - 1s 175us/step - loss: 3.8287 - mean_absolute_error: 3.8287 - val_loss: 6.8033 - val_mean_absolute_error: 6.8033\n",
      "Epoch 461/500\n",
      "3542/3542 [==============================] - 1s 191us/step - loss: 3.7962 - mean_absolute_error: 3.7962 - val_loss: 7.3529 - val_mean_absolute_error: 7.3529\n",
      "Epoch 462/500\n",
      "3542/3542 [==============================] - 1s 255us/step - loss: 3.6718 - mean_absolute_error: 3.6718 - val_loss: 7.0908 - val_mean_absolute_error: 7.0908\n",
      "Epoch 463/500\n",
      "3542/3542 [==============================] - 1s 246us/step - loss: 4.2169 - mean_absolute_error: 4.2169 - val_loss: 7.5695 - val_mean_absolute_error: 7.5695\n",
      "Epoch 464/500\n",
      "3542/3542 [==============================] - 1s 259us/step - loss: 3.9036 - mean_absolute_error: 3.9036 - val_loss: 7.0200 - val_mean_absolute_error: 7.0200\n",
      "Epoch 465/500\n",
      "3542/3542 [==============================] - 1s 211us/step - loss: 4.1836 - mean_absolute_error: 4.1836 - val_loss: 8.7814 - val_mean_absolute_error: 8.7814\n",
      "Epoch 466/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 3.6183 - mean_absolute_error: 3.6183 - val_loss: 7.0852 - val_mean_absolute_error: 7.0852\n",
      "Epoch 467/500\n",
      "3542/3542 [==============================] - 1s 184us/step - loss: 3.6351 - mean_absolute_error: 3.6351 - val_loss: 6.9286 - val_mean_absolute_error: 6.9286\n",
      "Epoch 468/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 4.0398 - mean_absolute_error: 4.0398 - val_loss: 8.8870 - val_mean_absolute_error: 8.8870\n",
      "Epoch 469/500\n",
      "3542/3542 [==============================] - 1s 241us/step - loss: 3.6665 - mean_absolute_error: 3.6665 - val_loss: 6.8011 - val_mean_absolute_error: 6.8011\n",
      "Epoch 470/500\n",
      "3542/3542 [==============================] - 1s 204us/step - loss: 3.7464 - mean_absolute_error: 3.7464 - val_loss: 7.3779 - val_mean_absolute_error: 7.3779\n",
      "Epoch 471/500\n",
      "3542/3542 [==============================] - 1s 214us/step - loss: 3.9379 - mean_absolute_error: 3.9379 - val_loss: 6.8190 - val_mean_absolute_error: 6.8190\n",
      "Epoch 472/500\n",
      "3542/3542 [==============================] - 1s 223us/step - loss: 3.6357 - mean_absolute_error: 3.6357 - val_loss: 7.1867 - val_mean_absolute_error: 7.1867\n",
      "Epoch 473/500\n",
      "3542/3542 [==============================] - 1s 225us/step - loss: 3.9808 - mean_absolute_error: 3.9808 - val_loss: 7.0125 - val_mean_absolute_error: 7.0125\n",
      "Epoch 474/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 3.7595 - mean_absolute_error: 3.7595 - val_loss: 7.3446 - val_mean_absolute_error: 7.3446\n",
      "Epoch 475/500\n",
      "3542/3542 [==============================] - 1s 205us/step - loss: 3.8300 - mean_absolute_error: 3.8300 - val_loss: 7.2912 - val_mean_absolute_error: 7.2912\n",
      "Epoch 476/500\n",
      "3542/3542 [==============================] - 1s 228us/step - loss: 3.8865 - mean_absolute_error: 3.8865 - val_loss: 6.8657 - val_mean_absolute_error: 6.8657\n",
      "Epoch 477/500\n",
      "3542/3542 [==============================] - 1s 240us/step - loss: 4.1469 - mean_absolute_error: 4.1469 - val_loss: 6.8759 - val_mean_absolute_error: 6.8759\n",
      "Epoch 478/500\n",
      "3542/3542 [==============================] - 1s 223us/step - loss: 3.7543 - mean_absolute_error: 3.7543 - val_loss: 6.8730 - val_mean_absolute_error: 6.8730\n",
      "Epoch 479/500\n",
      "3542/3542 [==============================] - 1s 188us/step - loss: 3.7163 - mean_absolute_error: 3.7163 - val_loss: 7.5677 - val_mean_absolute_error: 7.5677\n",
      "Epoch 480/500\n",
      "3542/3542 [==============================] - 1s 257us/step - loss: 3.7742 - mean_absolute_error: 3.7742 - val_loss: 6.6136 - val_mean_absolute_error: 6.6136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500\n",
      "3542/3542 [==============================] - 1s 264us/step - loss: 3.8242 - mean_absolute_error: 3.8242 - val_loss: 6.8126 - val_mean_absolute_error: 6.8126\n",
      "Epoch 482/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 3.6294 - mean_absolute_error: 3.6294 - val_loss: 6.8998 - val_mean_absolute_error: 6.8998\n",
      "Epoch 483/500\n",
      "3542/3542 [==============================] - 1s 244us/step - loss: 3.6146 - mean_absolute_error: 3.6146 - val_loss: 6.9226 - val_mean_absolute_error: 6.9226\n",
      "Epoch 484/500\n",
      "3542/3542 [==============================] - 1s 258us/step - loss: 3.7589 - mean_absolute_error: 3.7589 - val_loss: 7.4207 - val_mean_absolute_error: 7.4207\n",
      "Epoch 485/500\n",
      "3542/3542 [==============================] - 1s 221us/step - loss: 4.2216 - mean_absolute_error: 4.2216 - val_loss: 6.9122 - val_mean_absolute_error: 6.9122\n",
      "Epoch 486/500\n",
      "3542/3542 [==============================] - 1s 180us/step - loss: 3.8109 - mean_absolute_error: 3.8109 - val_loss: 7.1077 - val_mean_absolute_error: 7.1077\n",
      "Epoch 487/500\n",
      "3542/3542 [==============================] - 1s 212us/step - loss: 3.8499 - mean_absolute_error: 3.8499 - val_loss: 6.8081 - val_mean_absolute_error: 6.8081\n",
      "Epoch 488/500\n",
      "3542/3542 [==============================] - 1s 213us/step - loss: 3.7081 - mean_absolute_error: 3.7081 - val_loss: 6.8928 - val_mean_absolute_error: 6.8928\n",
      "Epoch 489/500\n",
      "3542/3542 [==============================] - 1s 208us/step - loss: 4.5309 - mean_absolute_error: 4.5309 - val_loss: 7.3007 - val_mean_absolute_error: 7.3007\n",
      "Epoch 490/500\n",
      "3542/3542 [==============================] - 1s 172us/step - loss: 4.0059 - mean_absolute_error: 4.0059 - val_loss: 7.1684 - val_mean_absolute_error: 7.1684\n",
      "Epoch 491/500\n",
      "3542/3542 [==============================] - 1s 210us/step - loss: 3.6057 - mean_absolute_error: 3.6057 - val_loss: 6.7340 - val_mean_absolute_error: 6.7340\n",
      "Epoch 492/500\n",
      "3542/3542 [==============================] - 1s 269us/step - loss: 3.9017 - mean_absolute_error: 3.9017 - val_loss: 6.8399 - val_mean_absolute_error: 6.8399\n",
      "Epoch 493/500\n",
      "3542/3542 [==============================] - 1s 177us/step - loss: 3.7836 - mean_absolute_error: 3.7836 - val_loss: 7.4089 - val_mean_absolute_error: 7.4089\n",
      "Epoch 494/500\n",
      "3542/3542 [==============================] - 1s 185us/step - loss: 4.3180 - mean_absolute_error: 4.3180 - val_loss: 10.4172 - val_mean_absolute_error: 10.4172\n",
      "Epoch 495/500\n",
      "3542/3542 [==============================] - 1s 200us/step - loss: 4.6081 - mean_absolute_error: 4.6081 - val_loss: 7.0301 - val_mean_absolute_error: 7.0301\n",
      "Epoch 496/500\n",
      "3542/3542 [==============================] - 1s 207us/step - loss: 4.5242 - mean_absolute_error: 4.5242 - val_loss: 8.5535 - val_mean_absolute_error: 8.5535\n",
      "Epoch 497/500\n",
      "3542/3542 [==============================] - 1s 215us/step - loss: 3.8397 - mean_absolute_error: 3.8397 - val_loss: 7.4290 - val_mean_absolute_error: 7.4290\n",
      "Epoch 498/500\n",
      "3542/3542 [==============================] - 1s 229us/step - loss: 3.5953 - mean_absolute_error: 3.5953 - val_loss: 6.7578 - val_mean_absolute_error: 6.7578\n",
      "Epoch 499/500\n",
      "3542/3542 [==============================] - 1s 228us/step - loss: 3.5591 - mean_absolute_error: 3.5591 - val_loss: 7.0130 - val_mean_absolute_error: 7.0130\n",
      "Epoch 500/500\n",
      "3542/3542 [==============================] - 1s 223us/step - loss: 3.5951 - mean_absolute_error: 3.5951 - val_loss: 7.1379 - val_mean_absolute_error: 7.1379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb0c0b4bfd0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(x_train, y_train, epochs=500, batch_size=32, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = NN_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 413.08601574260456\n",
      "\n",
      "RMSE: 20.32451760171947\n",
      "\n",
      "MAE: 6.515900369446747\n",
      "\n",
      "r2score: 0.985457129717469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_metrics(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation by SVD for Veg and Non-Veg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_g</th>\n",
       "      <th>Fat_g</th>\n",
       "      <th>Carb_g</th>\n",
       "      <th>Sugar_g</th>\n",
       "      <th>Fiber_g</th>\n",
       "      <th>VitA_mcg</th>\n",
       "      <th>VitB6_mg</th>\n",
       "      <th>VitB12_mcg</th>\n",
       "      <th>VitC_mg</th>\n",
       "      <th>VitE_mg</th>\n",
       "      <th>...</th>\n",
       "      <th>Folate_USRDA</th>\n",
       "      <th>Niacin_USRDA</th>\n",
       "      <th>Riboflavin_USRDA</th>\n",
       "      <th>Thiamin_USRDA</th>\n",
       "      <th>Calcium_USRDA</th>\n",
       "      <th>Copper_USRDA</th>\n",
       "      <th>Magnesium_USRDA</th>\n",
       "      <th>Phosphorus_USRDA</th>\n",
       "      <th>Selenium_USRDA</th>\n",
       "      <th>Zinc_USRDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.85</td>\n",
       "      <td>81.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.032857</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.28</td>\n",
       "      <td>99.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.40</td>\n",
       "      <td>28.74</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>0.293846</td>\n",
       "      <td>0.024167</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.054762</td>\n",
       "      <td>0.552857</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.241818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.24</td>\n",
       "      <td>29.68</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>0.065</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.007375</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.011667</td>\n",
       "      <td>0.561667</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.644286</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Protein_g  Fat_g  Carb_g  Sugar_g  Fiber_g  VitA_mcg  VitB6_mg  VitB12_mcg  \\\n",
       "0       0.85  81.11    0.06     0.06      0.0     684.0     0.003        0.17   \n",
       "1       0.85  81.11    0.06     0.06      0.0     684.0     0.003        0.13   \n",
       "2       0.28  99.48    0.00     0.00      0.0     840.0     0.001        0.01   \n",
       "3      21.40  28.74    2.34     0.50      0.0     198.0     0.166        1.22   \n",
       "4      23.24  29.68    2.79     0.51      0.0     292.0     0.065        1.26   \n",
       "\n",
       "   VitC_mg  VitE_mg  ...  Folate_USRDA  Niacin_USRDA  Riboflavin_USRDA  \\\n",
       "0      0.0     2.32  ...        0.0075      0.002625          0.026154   \n",
       "1      0.0     2.32  ...        0.0075      0.002625          0.026154   \n",
       "2      0.0     2.80  ...        0.0000      0.000188          0.003846   \n",
       "3      0.0     0.25  ...        0.0900      0.063500          0.293846   \n",
       "4      0.0     0.26  ...        0.0500      0.007375          0.270000   \n",
       "\n",
       "   Thiamin_USRDA  Calcium_USRDA  Copper_USRDA  Magnesium_USRDA  \\\n",
       "0       0.004167       0.020000      0.000000         0.004762   \n",
       "1       0.004167       0.020000      0.000018         0.004762   \n",
       "2       0.000833       0.003333      0.000001         0.000000   \n",
       "3       0.024167       0.440000      0.000044         0.054762   \n",
       "4       0.011667       0.561667      0.000027         0.057143   \n",
       "\n",
       "   Phosphorus_USRDA  Selenium_USRDA  Zinc_USRDA  \n",
       "0          0.034286        0.018182    0.008182  \n",
       "1          0.032857        0.018182    0.004545  \n",
       "2          0.004286        0.000000    0.000909  \n",
       "3          0.552857        0.263636    0.241818  \n",
       "4          0.644286        0.263636    0.236364  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = svd.fit_transform(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7229, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Non-Veg\n",
       "1       Non-Veg\n",
       "2       Non-Veg\n",
       "3       Non-Veg\n",
       "4       Non-Veg\n",
       "         ...   \n",
       "8613    Non-Veg\n",
       "8614    Non-Veg\n",
       "8615        Veg\n",
       "8616    Non-Veg\n",
       "8617    Non-Veg\n",
       "Name: FoodGroup, Length: 7229, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7229"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7229, 2)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "data1 = copy.deepcopy(data)\n",
    "datan = np.array(data1)\n",
    "label = list(label)\n",
    "dic={}\n",
    "for i in range(0,len(datan)):\n",
    "    #print( datan[i][0] , datan[i][1] , datan[i][2] )\n",
    "    try:\n",
    "        #print(label[i],i)\n",
    "        dic[label[i]].append ([new_data[i][0],new_data[i][1]])\n",
    "    except:\n",
    "        #print(label[i])\n",
    "        dic[label[i]] = []\n",
    "        dic[label[i]].append ([new_data[i][0],new_data[i][1]])\n",
    "    #print( datan[i][0] , dic[datan[i][0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3057"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic['Non-Veg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"SVD visualisation\")\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "colors=['#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe','#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000']\n",
    "l=0\n",
    "for type in dic.keys():\n",
    "    #plt.plot(new_data[i,0:1], new_data[i,1:2], color=colors[l],ls='None')\n",
    "    plt.scatter(np.array(dic[type])[:,0],np.array(dic[type])[:,1], color=colors[l],label = type)\n",
    "    plt.legend(loc=\"best\")\n",
    "    l+=1\n",
    "    #plt.xlim([-5, 6])\n",
    "    #plt.ylim([-5, 5])\n",
    "#plt.savefig(name)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7229, 38)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
